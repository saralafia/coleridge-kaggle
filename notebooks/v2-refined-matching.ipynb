{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refined matching V2\n",
    "A second attempt solution for smarter string matching with more labels ([Score](https://www.kaggle.com/c/coleridgeinitiative-show-us-the-data/leaderboard): 0.48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from itertools import chain\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defined by the competition: `clean_text` and evaluate the token-based `jaccard` similarity evaluation function given by the competition:\n",
    "- it compares the intersection of a set of strings against a \"groundtruth\" set of strings\n",
    "- solutions must be sorted alphabetically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/nfs/turbo/hrg/coleridge/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(txt):\n",
    "    \"\"\"\n",
    "    defined by the competition\n",
    "    \"\"\"\n",
    "    return re.sub('[^A-Za-z0-9]+', ' ', txt.lower())\n",
    "\n",
    "def remove_stops(txt):\n",
    "    return [ re.sub(' +', ' ', re.sub('[^A-Za-z0-9\\[\\]]+', ' ', str(r).lower()).strip()) for r in txt if not r.lower() in stop_words  ]\n",
    "\n",
    "def jaccard(str1, str2): \n",
    "    \"\"\"\n",
    "    defined by the competition\n",
    "    \"\"\"\n",
    "    a = set(str1.lower().split()) \n",
    "    b = set(str2.lower().split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
    "\n",
    "def extract_acronyms(txt):\n",
    "    \"\"\"\n",
    "    finds and returns a sequence of capital letters\n",
    "    for use on dataset_titles, dataset_labels, or full text\n",
    "    \"\"\"\n",
    "    matches = re.findall(r\"\\b[A-Z\\.]{2,}s?\\b\", txt)\n",
    "    if matches:\n",
    "        return matches\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def flatten_list(object):\n",
    "    \"\"\"\n",
    "    unnests labels\n",
    "    \"\"\"\n",
    "    gather = []\n",
    "    for item in object:\n",
    "        if isinstance(item, (list, tuple, set)):\n",
    "            gather.extend(flatten_list(item))            \n",
    "        else:\n",
    "            gather.append(item)\n",
    "    return gather\n",
    "\n",
    "def filter_set(main_set, condition):\n",
    "    \"\"\"\n",
    "    used to remove items from label set based on a condition\n",
    "    \"\"\"\n",
    "    for elem in list(main_set):\n",
    "        if condition(elem):\n",
    "            main_set.discard(elem)\n",
    "\n",
    "# def search_window(section, phrase, window_size):\n",
    "#     \"\"\"\n",
    "#     defines a section to search, a search phrase, and a text window size to return\n",
    "#     for use on full text as a preprocessing step\n",
    "#     \"\"\"\n",
    "#     section = section.split()\n",
    "#     phrase = phrase.split()\n",
    "#     words = len(phrase)\n",
    "\n",
    "#     for i, word in enumerate(section):\n",
    "#         if word == phrase[0] and section[i:i+words] == phrase:\n",
    "#             start = max(0, i-window_size)\n",
    "#             return ' '.join(section[start:i+words+window_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['take', 'january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', 'october', 'november', 'december'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.read_csv('../data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = '../data/train/'\n",
    "\n",
    "papers = {}\n",
    "\n",
    "for paper_id in df_train['Id']:\n",
    "    with open(f'{train_files}/{paper_id}.json', 'r') as f:\n",
    "        paper = json.load(f)\n",
    "        papers[paper_id] = paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = '../data/test/'\n",
    "\n",
    "for paper_id in submission_df['Id'].unique():\n",
    "    with open(f'{test_files}/{paper_id}.json', 'r') as f:\n",
    "        paper = json.load(f)\n",
    "        papers[paper_id] = paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load ICPSR study titles and series titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ABC News/Washington Post Poll Series</td>\n",
       "      <td>abc news washington post poll series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>American Housing Survey Series</td>\n",
       "      <td>american housing survey series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>American National Election Study (ANES) Series</td>\n",
       "      <td>american national election study anes series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>American Public Opinion and United States Fore...</td>\n",
       "      <td>american public opinion and united states fore...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Annual Survey of Governments Series</td>\n",
       "      <td>annual survey of governments series</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                              TITLE  \\\n",
       "0   1               ABC News/Washington Post Poll Series   \n",
       "1   2                     American Housing Survey Series   \n",
       "2   3     American National Election Study (ANES) Series   \n",
       "3   4  American Public Opinion and United States Fore...   \n",
       "4   5                Annual Survey of Governments Series   \n",
       "\n",
       "                                               clean  \n",
       "0               abc news washington post poll series  \n",
       "1                     american housing survey series  \n",
       "2       american national election study anes series  \n",
       "3  american public opinion and united states fore...  \n",
       "4                annual survey of governments series  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_icpsr_studies = pd.read_csv(DATA_DIR + 'labels/icpsr_studies.csv')\n",
    "all_icpsr_studies['clean'] = all_icpsr_studies['NAME'].apply(clean_text).str.replace('\\d+', '')\n",
    "all_icpsr_studies = all_icpsr_studies[all_icpsr_studies['clean'].str.contains(' ')]\n",
    "# all_icpsr_studies.head()\n",
    "\n",
    "all_icspr_series = pd.read_csv(DATA_DIR + 'labels/icpsr_series.csv')\n",
    "all_icspr_series['TITLE'] = all_icspr_series['TITLE'].astype(str)\n",
    "all_icspr_series['clean'] = all_icspr_series['TITLE'].apply(clean_text).str.replace('\\d+', '')\n",
    "all_icspr_series = all_icspr_series[all_icspr_series['clean'].str.contains(' ')]\n",
    "all_icspr_series.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data titles (n=299,743) harvested from Data.gov CKAN (on 6/4/21)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>name</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0-2-second-spectral-response-acceleration-5-of...</td>\n",
       "      <td>1</td>\n",
       "      <td>second spectral response acceleration  of cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0-25-degree-gfs-for-aoos-region</td>\n",
       "      <td>1</td>\n",
       "      <td>degree gfs for aoos region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0-25-degree-gfs-for-aoos-region1</td>\n",
       "      <td>1</td>\n",
       "      <td>degree gfs for aoos region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0-25-degree-gfs-for-aoos-region2</td>\n",
       "      <td>1</td>\n",
       "      <td>degree gfs for aoos region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0-25-degree-gfs-for-aoos-region3</td>\n",
       "      <td>1</td>\n",
       "      <td>degree gfs for aoos region</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              index  name  \\\n",
       "0           0  0-2-second-spectral-response-acceleration-5-of...     1   \n",
       "1           1                    0-25-degree-gfs-for-aoos-region     1   \n",
       "2           2                   0-25-degree-gfs-for-aoos-region1     1   \n",
       "3           3                   0-25-degree-gfs-for-aoos-region2     1   \n",
       "4           4                   0-25-degree-gfs-for-aoos-region3     1   \n",
       "\n",
       "                                               clean  \n",
       "0    second spectral response acceleration  of cr...  \n",
       "1                         degree gfs for aoos region  \n",
       "2                         degree gfs for aoos region  \n",
       "3                         degree gfs for aoos region  \n",
       "4                         degree gfs for aoos region  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_datagov_titles = pd.read_csv(DATA_DIR + 'labels/ckan_data_gov_names.csv')\n",
    "all_datagov_titles['clean'] = all_datagov_titles['index'].apply(clean_text).str.replace('\\d+', '')\n",
    "all_datagov_titles = all_datagov_titles[all_datagov_titles['clean'].str.contains(' ')]\n",
    "all_datagov_titles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other data posted to Kaggle (unknown origin, probably from Data.gov pull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>noaa c cap</td>\n",
       "      <td>noaa c cap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>noaa c-cap</td>\n",
       "      <td>noaa c cap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>slosh model</td>\n",
       "      <td>slosh model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>noaa tide gauge</td>\n",
       "      <td>noaa tide gauge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>noaa tide station</td>\n",
       "      <td>noaa tide station</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               title              clean\n",
       "3         noaa c cap         noaa c cap\n",
       "4         noaa c-cap         noaa c cap\n",
       "5        slosh model        slosh model\n",
       "6    noaa tide gauge    noaa tide gauge\n",
       "7  noaa tide station  noaa tide station"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datagov_labels = pd.read_csv(DATA_DIR + 'labels/kaggle_data_800.csv')\n",
    "datagov_labels['clean'] = datagov_labels['title'].apply(clean_text).str.replace('\\d+', '')\n",
    "datagov_labels = datagov_labels[datagov_labels['clean'].str.contains(' ')]\n",
    "datagov_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract acronyms from data labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>pub_title</th>\n",
       "      <th>dataset_title</th>\n",
       "      <th>dataset_label</th>\n",
       "      <th>cleaned_label</th>\n",
       "      <th>extract_acronyms_title</th>\n",
       "      <th>extract_acronyms_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d0fa7568-7d8e-4db9-870f-f9c6f668c17b</td>\n",
       "      <td>The Impact of Dual Enrollment on College Degre...</td>\n",
       "      <td>National Education Longitudinal Study</td>\n",
       "      <td>National Education Longitudinal Study</td>\n",
       "      <td>national education longitudinal study</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2f26f645-3dec-485d-b68d-f013c9e05e60</td>\n",
       "      <td>Educational Attainment of High School Dropouts...</td>\n",
       "      <td>National Education Longitudinal Study</td>\n",
       "      <td>National Education Longitudinal Study</td>\n",
       "      <td>national education longitudinal study</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c5d5cd2c-59de-4f29-bbb1-6a88c7b52f29</td>\n",
       "      <td>Differences in Outcomes for Female and Male St...</td>\n",
       "      <td>National Education Longitudinal Study</td>\n",
       "      <td>National Education Longitudinal Study</td>\n",
       "      <td>national education longitudinal study</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5c9a3bc9-41ba-4574-ad71-e25c1442c8af</td>\n",
       "      <td>Stepping Stone and Option Value in a Model of ...</td>\n",
       "      <td>National Education Longitudinal Study</td>\n",
       "      <td>National Education Longitudinal Study</td>\n",
       "      <td>national education longitudinal study</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c754dec7-c5a3-4337-9892-c02158475064</td>\n",
       "      <td>Parental Effort, School Resources, and Student...</td>\n",
       "      <td>National Education Longitudinal Study</td>\n",
       "      <td>National Education Longitudinal Study</td>\n",
       "      <td>national education longitudinal study</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19656</th>\n",
       "      <td>b3498176-8832-4033-aea6-b5ea85ea04c4</td>\n",
       "      <td>RSNA International Trends: A Global Perspectiv...</td>\n",
       "      <td>RSNA International COVID-19 Open Radiology Dat...</td>\n",
       "      <td>RSNA International COVID Open Radiology Database</td>\n",
       "      <td>rsna international covid open radiology database</td>\n",
       "      <td>[RSNA, COVID, RICORD]</td>\n",
       "      <td>[RSNA, COVID]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19657</th>\n",
       "      <td>f77eb51f-c3ac-420b-9586-cb187849c321</td>\n",
       "      <td>MCCS: a novel recognition pattern-based method...</td>\n",
       "      <td>CAS COVID-19 antiviral candidate compounds dat...</td>\n",
       "      <td>CAS COVID-19 antiviral candidate compounds dat...</td>\n",
       "      <td>cas covid 19 antiviral candidate compounds dat...</td>\n",
       "      <td>[CAS, COVID]</td>\n",
       "      <td>[CAS, COVID]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19658</th>\n",
       "      <td>ab59bcdd-7b7c-4107-93f5-0ccaf749236c</td>\n",
       "      <td>Quantitative Structure–Activity Relationship M...</td>\n",
       "      <td>CAS COVID-19 antiviral candidate compounds dat...</td>\n",
       "      <td>CAS COVID-19 antiviral candidate compounds dat...</td>\n",
       "      <td>cas covid 19 antiviral candidate compounds dat...</td>\n",
       "      <td>[CAS, COVID]</td>\n",
       "      <td>[CAS, COVID]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19659</th>\n",
       "      <td>fd23e7e0-a5d2-4f98-992d-9209c85153bb</td>\n",
       "      <td>A ligand-based computational drug repurposing ...</td>\n",
       "      <td>CAS COVID-19 antiviral candidate compounds dat...</td>\n",
       "      <td>CAS COVID-19 antiviral candidate compounds dat...</td>\n",
       "      <td>cas covid 19 antiviral candidate compounds dat...</td>\n",
       "      <td>[CAS, COVID]</td>\n",
       "      <td>[CAS, COVID]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19660</th>\n",
       "      <td>fd23e7e0-a5d2-4f98-992d-9209c85153bb</td>\n",
       "      <td>A ligand-based computational drug repurposing ...</td>\n",
       "      <td>CAS COVID-19 antiviral candidate compounds dat...</td>\n",
       "      <td>CAS COVID-19 antiviral candidate compounds data</td>\n",
       "      <td>cas covid 19 antiviral candidate compounds data</td>\n",
       "      <td>[CAS, COVID]</td>\n",
       "      <td>[CAS, COVID]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19661 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Id  \\\n",
       "0      d0fa7568-7d8e-4db9-870f-f9c6f668c17b   \n",
       "1      2f26f645-3dec-485d-b68d-f013c9e05e60   \n",
       "2      c5d5cd2c-59de-4f29-bbb1-6a88c7b52f29   \n",
       "3      5c9a3bc9-41ba-4574-ad71-e25c1442c8af   \n",
       "4      c754dec7-c5a3-4337-9892-c02158475064   \n",
       "...                                     ...   \n",
       "19656  b3498176-8832-4033-aea6-b5ea85ea04c4   \n",
       "19657  f77eb51f-c3ac-420b-9586-cb187849c321   \n",
       "19658  ab59bcdd-7b7c-4107-93f5-0ccaf749236c   \n",
       "19659  fd23e7e0-a5d2-4f98-992d-9209c85153bb   \n",
       "19660  fd23e7e0-a5d2-4f98-992d-9209c85153bb   \n",
       "\n",
       "                                               pub_title  \\\n",
       "0      The Impact of Dual Enrollment on College Degre...   \n",
       "1      Educational Attainment of High School Dropouts...   \n",
       "2      Differences in Outcomes for Female and Male St...   \n",
       "3      Stepping Stone and Option Value in a Model of ...   \n",
       "4      Parental Effort, School Resources, and Student...   \n",
       "...                                                  ...   \n",
       "19656  RSNA International Trends: A Global Perspectiv...   \n",
       "19657  MCCS: a novel recognition pattern-based method...   \n",
       "19658  Quantitative Structure–Activity Relationship M...   \n",
       "19659  A ligand-based computational drug repurposing ...   \n",
       "19660  A ligand-based computational drug repurposing ...   \n",
       "\n",
       "                                           dataset_title  \\\n",
       "0                  National Education Longitudinal Study   \n",
       "1                  National Education Longitudinal Study   \n",
       "2                  National Education Longitudinal Study   \n",
       "3                  National Education Longitudinal Study   \n",
       "4                  National Education Longitudinal Study   \n",
       "...                                                  ...   \n",
       "19656  RSNA International COVID-19 Open Radiology Dat...   \n",
       "19657  CAS COVID-19 antiviral candidate compounds dat...   \n",
       "19658  CAS COVID-19 antiviral candidate compounds dat...   \n",
       "19659  CAS COVID-19 antiviral candidate compounds dat...   \n",
       "19660  CAS COVID-19 antiviral candidate compounds dat...   \n",
       "\n",
       "                                           dataset_label  \\\n",
       "0                  National Education Longitudinal Study   \n",
       "1                  National Education Longitudinal Study   \n",
       "2                  National Education Longitudinal Study   \n",
       "3                  National Education Longitudinal Study   \n",
       "4                  National Education Longitudinal Study   \n",
       "...                                                  ...   \n",
       "19656   RSNA International COVID Open Radiology Database   \n",
       "19657  CAS COVID-19 antiviral candidate compounds dat...   \n",
       "19658  CAS COVID-19 antiviral candidate compounds dat...   \n",
       "19659  CAS COVID-19 antiviral candidate compounds dat...   \n",
       "19660    CAS COVID-19 antiviral candidate compounds data   \n",
       "\n",
       "                                           cleaned_label  \\\n",
       "0                  national education longitudinal study   \n",
       "1                  national education longitudinal study   \n",
       "2                  national education longitudinal study   \n",
       "3                  national education longitudinal study   \n",
       "4                  national education longitudinal study   \n",
       "...                                                  ...   \n",
       "19656   rsna international covid open radiology database   \n",
       "19657  cas covid 19 antiviral candidate compounds dat...   \n",
       "19658  cas covid 19 antiviral candidate compounds dat...   \n",
       "19659  cas covid 19 antiviral candidate compounds dat...   \n",
       "19660    cas covid 19 antiviral candidate compounds data   \n",
       "\n",
       "      extract_acronyms_title extract_acronyms_label  \n",
       "0                       None                   None  \n",
       "1                       None                   None  \n",
       "2                       None                   None  \n",
       "3                       None                   None  \n",
       "4                       None                   None  \n",
       "...                      ...                    ...  \n",
       "19656  [RSNA, COVID, RICORD]          [RSNA, COVID]  \n",
       "19657           [CAS, COVID]           [CAS, COVID]  \n",
       "19658           [CAS, COVID]           [CAS, COVID]  \n",
       "19659           [CAS, COVID]           [CAS, COVID]  \n",
       "19660           [CAS, COVID]           [CAS, COVID]  \n",
       "\n",
       "[19661 rows x 7 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['extract_acronyms_title'] = df_train['dataset_title'].apply(extract_acronyms)\n",
    "df_train['extract_acronyms_label'] = df_train['dataset_label'].apply(extract_acronyms)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra labels\n",
    "- Filter extra labels by length to reduce noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "490456"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_labels = set()\n",
    "    \n",
    "for label_1, label_2 in datagov_labels[['title', 'clean']].itertuples(index=False):\n",
    "    extra_labels.add(\"\".join(str(label_1)))\n",
    "    extra_labels.add(\"\".join(str(label_2)))\n",
    "\n",
    "for label_3, label_4 in all_datagov_titles[['index', 'clean']].itertuples(index=False):\n",
    "    extra_labels.add(\"\".join(str(label_3)))\n",
    "    extra_labels.add(\"\".join(str(label_4)))\n",
    "\n",
    "for label_5, label_6 in all_icpsr_studies[['NAME', 'clean']].itertuples(index=False):\n",
    "    extra_labels.add(\"\".join(str(label_5)))\n",
    "    extra_labels.add(\"\".join(str(label_6)))\n",
    "\n",
    "for label_7, label_8 in all_icspr_series[['TITLE', 'clean']].itertuples(index=False):\n",
    "    extra_labels.add(\"\".join(str(label_7)))\n",
    "    extra_labels.add(\"\".join(str(label_8)))\n",
    "\n",
    "filter_set(extra_labels, lambda x : len(x) < 4)\n",
    "len(extra_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "379"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = set()\n",
    "for label_5, label_6, label_7, label_8, label_9 in df_train[['dataset_title', \n",
    "                                                               'dataset_label', \n",
    "                                                               'cleaned_label',\n",
    "                                                               'extract_acronyms_title', \n",
    "                                                               'extract_acronyms_label']].itertuples(index=False):\n",
    "    train_labels.add(\"\".join(str(label_5)))\n",
    "    train_labels.add(\"\".join(str(label_5)).lower())\n",
    "    train_labels.add(\"\".join(str(label_6)))\n",
    "    train_labels.add(\"\".join(str(label_6)).lower())\n",
    "    train_labels.add(\"\".join(str(label_7)))\n",
    "    train_labels.add(\"\".join(str(label_8)))\n",
    "    train_labels.add(\"\".join(str(label_8)).lower())\n",
    "    train_labels.add(\"\".join(str(label_9)))\n",
    "    train_labels.add(\"\".join(str(label_9)).lower())\n",
    "    \n",
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "490662"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels = set.union(extra_labels, train_labels) \n",
    "len(all_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "490660"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_labels = flatten_list(all_labels)\n",
    "flat_labels = [w.replace(\"['\", \"\") for w in flat_labels]\n",
    "flat_labels = [w.replace(\"']\", \"\") for w in flat_labels]\n",
    "flat_labels = [w.replace('\"', \"'\") for w in flat_labels]\n",
    "\n",
    "flat_labels.remove('None')\n",
    "flat_labels.remove('none')\n",
    "\n",
    "len(flat_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adni|alzheimer s disease neuroimaging initiative adni|alzheimer s disease neuroimaging initiative adni|california|cap|data a|database|figure|gene b|independence|nces|ng t\n",
      "addresses|administrative data|cap|colleges and universities|commerce|common core of data|current population|current population survey|data a|data e|data quality|database|earth|figure|integrated postsecondary education data system|international data base|international data base idb|international data base idb|line p|n leads|nces|nces common core of data|ng t|nsf|percent change|private schools|program for international student assessment|progress in international reading literacy study|salary schedule|school survey|schools and staffing survey|schools d|total population|trends in international mathematics and science study\n",
      "aerial imagery|avon|base flood elevation|beach nourishment|beach nourishment projects|building data|building footprints|cap|coastal area|code of federal regulations|data a|data quality|data set|database|diamond shoals|earth|figure|files|historic districts|historic landmarks|historic sites|holly|imagery|land area|land use|legislation|line p|national environmental policy act|national hydrography dataset|nces|ng t|noaa|noaa storm surge inundation|nsf|nws|parcels|parking lot|parks|public safety|review|sea lake and overland surges from hurricanes|slosh|slosh model|streets|usgs|wards|wilmington nc\n",
      "bureau of labor statistics|cap|data a|data e|drug stores|figure|food access research atlas|goal|grocery stores|grocery stores f|independence|median household income|nces|ng t|purchasing data|review|rural residents|rural urban continuum codes|urban areas|usda|zip codes\n"
     ]
    }
   ],
   "source": [
    "literal_preds = []\n",
    "\n",
    "for paper_id in submission_df['Id']:\n",
    "    paper = papers[paper_id]\n",
    "    text_1 = '. '.join(section['text'] for section in paper) #raw\n",
    "    text_2 = text_1.lower() #lowercase\n",
    "    text_3 = clean_text(text_1) #cleaned\n",
    "#     label = []\n",
    "    label = set() #is a set first to prevent capture of duplicates, then converted to a list to sort\n",
    "    for mention in flat_labels:\n",
    "        if mention in text_1 or mention in text_2 or mention in text_3:\n",
    "            label.add(clean_text(mention.strip())) #add if a set, append if a list\n",
    "    label_list = sorted(remove_stops(list(label)))\n",
    "    literal_preds.append('|'.join(label_list))\n",
    "\n",
    "for prediction in literal_preds:\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2100032a-7c33-4bff-97ef-690822c43466</td>\n",
       "      <td>adni|alzheimer s disease neuroimaging initiati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2f392438-e215-4169-bebf-21ac4ff253e1</td>\n",
       "      <td>addresses|administrative data|cap|colleges and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3f316b38-1a24-45a9-8d8c-4e05a42257c6</td>\n",
       "      <td>aerial imagery|avon|base flood elevation|beach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60</td>\n",
       "      <td>bureau of labor statistics|cap|data a|data e|d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Id  \\\n",
       "0  2100032a-7c33-4bff-97ef-690822c43466   \n",
       "1  2f392438-e215-4169-bebf-21ac4ff253e1   \n",
       "2  3f316b38-1a24-45a9-8d8c-4e05a42257c6   \n",
       "3  8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60   \n",
       "\n",
       "                                    PredictionString  \n",
       "0  adni|alzheimer s disease neuroimaging initiati...  \n",
       "1  addresses|administrative data|cap|colleges and...  \n",
       "2  aerial imagery|avon|base flood elevation|beach...  \n",
       "3  bureau of labor statistics|cap|data a|data e|d...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df['PredictionString'] = literal_preds\n",
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission_df.to_csv(\"../results/submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
