{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier & NER V3\n",
    "Third attempt solution with classifier (RF - balanced) and spaCy (NER) models (Score: unscored - notebook timedout on Kaggle)\n",
    "\n",
    "Workflow:\n",
    "1. tokenize test sentences\n",
    "2. pass test sentences through the binary classifier; retain sentences with high prob score\n",
    "3. pass high prob test sentences through the NER model; extract and append entity matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install spacy-transformers --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import re\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(txt):\n",
    "    return re.sub('[^A-Za-z0-9]+', ' ', str(txt).lower())\n",
    "\n",
    "def jaccard(str1, str2): \n",
    "    \"\"\"\n",
    "    defined by the competition\n",
    "    \"\"\"\n",
    "    a = set(str1.lower().split()) \n",
    "    b = set(str2.lower().split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
    "\n",
    "def clean_text(txt):\n",
    "    \"\"\"\n",
    "    Convert to lowercase, remove special characters, and punctuation.\n",
    "    \"\"\"\n",
    "    return re.sub('[^A-Za-z0-9]+', ' ', str(txt).lower())\n",
    "\n",
    "def find_acronyms(txt):\n",
    "    \"\"\"\n",
    "    finds and returns a sequence of capital letters\n",
    "    for use on dataset_titles, dataset_labels, or full text\n",
    "    \"\"\"\n",
    "    matches = re.findall(r\"\\b[A-Z\\.]{2,}s?\\b\", txt)\n",
    "    if matches:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def count_acronyms(txt):\n",
    "    \"\"\"\n",
    "    finds and returns a sequence of capital letters\n",
    "    for use on dataset_titles, dataset_labels, or full text\n",
    "    \"\"\"\n",
    "    matches = re.findall(r\"\\b[A-Z\\.]{2,}s?\\b\", txt)\n",
    "    if matches:\n",
    "        return len(matches)\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/nfs/turbo/hrg/coleridge/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_ner_model = spacy.load('/nfs/turbo/hrg/coleridge/spaCy/output/model-best') # output model is stored as \"model-best\" and \"model-last\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.read_csv('../data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>section_title</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>A significant body of research has been conduc...</td>\n",
       "      <td>a significant body of research has been conduc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60</td>\n",
       "      <td>Literature review</td>\n",
       "      <td>We reviewed the literature that explored retai...</td>\n",
       "      <td>we reviewed the literature that explored retai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60</td>\n",
       "      <td>Food shopping patterns: where do people shop?</td>\n",
       "      <td>Diversification in the food retail sector offe...</td>\n",
       "      <td>diversification in the food retail sector offe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60</td>\n",
       "      <td>Food shopping patterns: what do people buy?</td>\n",
       "      <td>Many factors, including income, participation ...</td>\n",
       "      <td>many factors including income participation in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60</td>\n",
       "      <td>2</td>\n",
       "      <td>Anne Palmer et al. shopping at the same store ...</td>\n",
       "      <td>anne palmer et al shopping at the same store h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Id  \\\n",
       "0  8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60   \n",
       "1  8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60   \n",
       "2  8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60   \n",
       "3  8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60   \n",
       "4  8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60   \n",
       "\n",
       "                                   section_title  \\\n",
       "0                                   Introduction   \n",
       "1                              Literature review   \n",
       "2  Food shopping patterns: where do people shop?   \n",
       "3    Food shopping patterns: what do people buy?   \n",
       "4                                              2   \n",
       "\n",
       "                                                text  \\\n",
       "0  A significant body of research has been conduc...   \n",
       "1  We reviewed the literature that explored retai...   \n",
       "2  Diversification in the food retail sector offe...   \n",
       "3  Many factors, including income, participation ...   \n",
       "4  Anne Palmer et al. shopping at the same store ...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  a significant body of research has been conduc...  \n",
       "1  we reviewed the literature that explored retai...  \n",
       "2  diversification in the food retail sector offe...  \n",
       "3  many factors including income participation in...  \n",
       "4  anne palmer et al shopping at the same store h...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_files = glob.glob('../data/test/*.json')\n",
    "\n",
    "df_test_pubs = pd.DataFrame()\n",
    "for test_file in test_files: \n",
    "    file_data = pd.read_json(test_file)\n",
    "    file_data.insert(0,'Id', test_file.split('/')[-1].split('.')[0])\n",
    "    df_test_pubs = pd.concat([df_test_pubs, file_data])\n",
    "\n",
    "df_test_pubs['clean_text'] = df_test_pubs['text'].apply(clean_text)\n",
    "df_test_pubs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target\n",
    "We are predicting whether a `sent` contains a data reference based on its features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>section_title</th>\n",
       "      <th>sent</th>\n",
       "      <th>sent_clean</th>\n",
       "      <th>section_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>A significant body of research has been conduc...</td>\n",
       "      <td>a significant body of research has been conduc...</td>\n",
       "      <td>introduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>Even though lowincome (LI) households' choice...</td>\n",
       "      <td>even though lowincome li households choices a...</td>\n",
       "      <td>introduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>Findings on purchasing patterns of LI househo...</td>\n",
       "      <td>findings on purchasing patterns of li househo...</td>\n",
       "      <td>introduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>Understanding the specific factors related to...</td>\n",
       "      <td>understanding the specific factors related to...</td>\n",
       "      <td>introduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>This study contributes to the literature by e...</td>\n",
       "      <td>this study contributes to the literature by e...</td>\n",
       "      <td>introduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2717</th>\n",
       "      <td>2100032a-7c33-4bff-97ef-690822c43466</td>\n",
       "      <td>Figure 1.</td>\n",
       "      <td>\\nTrampush et al</td>\n",
       "      <td>trampush et al</td>\n",
       "      <td>figure 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2718</th>\n",
       "      <td>2100032a-7c33-4bff-97ef-690822c43466</td>\n",
       "      <td>Figure 1.</td>\n",
       "      <td>Page 19   Table 3 Meta-analytic results of th...</td>\n",
       "      <td>page 19 table 3 meta analytic results of the ...</td>\n",
       "      <td>figure 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2719</th>\n",
       "      <td>2100032a-7c33-4bff-97ef-690822c43466</td>\n",
       "      <td>Figure 1.</td>\n",
       "      <td>1 associated with educational attainment in CO...</td>\n",
       "      <td>1 associated with educational attainment in co...</td>\n",
       "      <td>figure 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2720</th>\n",
       "      <td>2100032a-7c33-4bff-97ef-690822c43466</td>\n",
       "      <td>Figure 1.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>figure 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2721</th>\n",
       "      <td>2100032a-7c33-4bff-97ef-690822c43466</td>\n",
       "      <td>Consortium</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>consortium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2722 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Id section_title  \\\n",
       "0     8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60  Introduction   \n",
       "1     8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60  Introduction   \n",
       "2     8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60  Introduction   \n",
       "3     8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60  Introduction   \n",
       "4     8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60  Introduction   \n",
       "...                                    ...           ...   \n",
       "2717  2100032a-7c33-4bff-97ef-690822c43466     Figure 1.   \n",
       "2718  2100032a-7c33-4bff-97ef-690822c43466     Figure 1.   \n",
       "2719  2100032a-7c33-4bff-97ef-690822c43466     Figure 1.   \n",
       "2720  2100032a-7c33-4bff-97ef-690822c43466     Figure 1.   \n",
       "2721  2100032a-7c33-4bff-97ef-690822c43466    Consortium   \n",
       "\n",
       "                                                   sent  \\\n",
       "0     A significant body of research has been conduc...   \n",
       "1      Even though lowincome (LI) households' choice...   \n",
       "2      Findings on purchasing patterns of LI househo...   \n",
       "3      Understanding the specific factors related to...   \n",
       "4      This study contributes to the literature by e...   \n",
       "...                                                 ...   \n",
       "2717                                   \\nTrampush et al   \n",
       "2718   Page 19   Table 3 Meta-analytic results of th...   \n",
       "2719  1 associated with educational attainment in CO...   \n",
       "2720                                                      \n",
       "2721                                                      \n",
       "\n",
       "                                             sent_clean section_clean  \n",
       "0     a significant body of research has been conduc...  introduction  \n",
       "1      even though lowincome li households choices a...  introduction  \n",
       "2      findings on purchasing patterns of li househo...  introduction  \n",
       "3      understanding the specific factors related to...  introduction  \n",
       "4      this study contributes to the literature by e...  introduction  \n",
       "...                                                 ...           ...  \n",
       "2717                                     trampush et al     figure 1   \n",
       "2718   page 19 table 3 meta analytic results of the ...     figure 1   \n",
       "2719  1 associated with educational attainment in co...     figure 1   \n",
       "2720                                                        figure 1   \n",
       "2721                                                       consortium  \n",
       "\n",
       "[2722 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentences = []\n",
    "\n",
    "for row in df_test_pubs.itertuples():\n",
    "    sentences = row[3].split(\".\")\n",
    "    for sent in sentences:\n",
    "#     for sent in sent_tokenize(row[3]):\n",
    "        test_sentences.append((row[1], row[2], sent))\n",
    "\n",
    "df_test_sent = pd.DataFrame(test_sentences, columns=['Id', 'section_title', 'sent'])\n",
    "\n",
    "df_test_sent['sent'] = df_test_sent['sent'].astype(str)\n",
    "df_test_sent['section_title'] = df_test_sent['section_title'].astype(str)\n",
    "\n",
    "df_test_sent['sent_clean'] = df_test_sent['sent'].apply(clean_text)\n",
    "df_test_sent['section_clean']= df_test_sent['section_title'].apply(clean_text)\n",
    "\n",
    "df_test_sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply NER model to all test sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> Participants' county of residence was linked with the USDA (2013) \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Rural-Urban Continuum Codes\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       " (RUCCs) (United States Department of Agriculture, 2013) to determine if the household was located in an urban or rural area</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> Prior directly relevant assessments of sea level rise include Titus and Wang (2008) and the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    NC Sea Level Rise Risk Management Study\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       " (SLRRMS)</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> The \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    SLOSH MEOWs\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       " are a composite product that is produced from thousands of model runs with the same category, forward speed, storm trajectory, and initial tide level</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> The \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    SLOSH MOMs\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       " provide a worst case scenario product as they are compiled based on the maximum storm surge height for all hurricanes of a given category regardless of forward speed, storm trajectory, or landfall location</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> The adopted methodology incorporates techniques adapted from the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    NOAA Storm Surge\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       " Inundation Mapping guide, NC SLRRMS, and several projects conducted at East Carolina University</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> The principal data include: 1) the newest NOAA National Hurricane Center (NHC) Sea, Lake, and Overland Surges from Hurricanes (\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    SLOSH) basin models\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       "; 2) Historic Districts and specific historic structure building  Table 3</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">) Storm surge modeling data was obtained from the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    SLOSH display\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       " program and used to map the extent and depth of inundation resulting from various storm scenarios ( Figure 6)</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> The \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    SLOSH model\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       " was developed by the National Weather Service's NHC to estimate storm surge from hurricanes using storm properties (e</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> The newest available \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    SLOSH grids\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       " for the Hatteras area were obtained and coregistered to the NC LiDAR, building footprints, and other GIS datasets</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Mapping the storm surge inundation involved exporting the data from the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    SLOSH display\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       " program that contained the height of the storm surge that was modeled using the MOMs approach for the Cape Hatteras/Pamlico Sound (ht3) Basin for each category storm that occurred during high tide ( Figure 7)</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> The \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    SLOSH display\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       " program exports the data as a shapefile in WGS84</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> Additional fields were added to each attribute table, and the appropriate value was added to the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    SLOSH output\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       " to simulate the height of the storm surge that would occur under different sea level rise scenarios of 20, 40, 70, 100, and 140 cm</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> The Spline interpolation method was used to create a water surface based on the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    SLOSH point\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       " attributes at a 5-m resolution</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> Across much of the region today, a category 2 storm surge of a nearby landfalling hurricane is required to inundation most areas of the Outer Banks in our modeling with \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    SLOSH and\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       " LiDAR DEMs</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">This section presents results of site level vulnerability assessment, focusing on the historic structures and landmarks for each district and their elevation relationship between finished first floors (FFE) and the height of \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    SLOSH storm\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       " surge models with sea level rise</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> Figure 18 portrays some of the underlying data, a \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    SLOSH inundation grid\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       " superimposed on the LiDAR DEM with building centroids and footprints (inset A and B)</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> Columns reference the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    SLOSH Safir\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       "-Simpson categories, and each table represents a distinct SLR scenario</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> The FFEs of the structures are higher than the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    SLOSH MOM\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       " surges for most category 1 storms (of course, non-inclusive of superimposed wave action</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">The NC \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Coastal Erosion Study\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       " (2016) published by NC DCM provides a thorough review of the efforts that have been conducted by federal, state, and local governments, as well as academia, to study and address ocean coastal erosion</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> The USGS has developed the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Coastal Change Hazards Portal\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       ", which provides interactive web mapping capabilities and downloadable data layers to analyze coastal change science along our Nation's coast</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> We were fortuitous with the release of a new \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    SLOSH grid\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       " for the Hatteras region by the NWS National Hurricane Center, allowing some improvement to the downscaling of MOM inundation maps</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> Static SLR and \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    SLOSH grids\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       ", LiDAR DEMs, and shoreline data, for instance, could be assimilated in models such as the Sea Level Affecting Marshes Model (SLAMM) to evaluate marsh fragmentation, loss, or migration up elevation</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> Comparative Indicators of Education in the United States and Other G-8 Countries: 2009 draws on the most current information about education from four primary sources: the Indicators of National Education Systems (INES) at the Organization for Economic Cooperation and Development (OECD); the Progress in International reading Literacy Study (PIrLS); the Program for International Student Assessment (PISA); and the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Trends in International Mathematics and Science Study\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       " (TIMSS)</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> these projects include the Indicators of national Education Systems (InES) at the organization for Economic cooperation and development (oEcd); the Progress in International reading Literacy Study (PIrLS); the Program for International Student Assessment (PISA); and the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    trends in International Mathematics and Science Study\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       " (tIMSS)</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> Census Bureau, the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    NCES Common Core of Data\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       " (CCD), the NCES Integrated Postsecondary Education Data System (IPEDS), and the NCES Schools and Staffing Survey (SASS)</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> These benchmarks are identical to the cutpoints used for the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Trends in International Mathematics and Science Study\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       " (TIMSS)</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> Using eighth-grade data from the 2007 \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Trends in International Mathematics and Science Study\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       " (TIMSS 2007), this indicator presents school principals' reports of both the incidence of behaviors that threaten a safe and orderly environment and their perceptions of these behaviors as a &quot;serious&quot; problem</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">This indicator presents the percentages of fourth-and eighthgraders reaching the four international benchmarks in science (low, intermediate, high, and advanced) in the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Trends in International Mathematics and Science Study\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       " (TIMSS) in 2007</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">   This indicator addresses differences by sex in science achievement among fourth-and eighth-grade students in the G-8 countries that participated in the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Trends in International Mathematics and Science Study\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       " (TIMSS) in 2007</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> Finally, several publicly available datasets were included; we kindly thank the investigative teams and staffs of the Pediatric Imaging, Neurocognition, and Genetics (PING) study, the Alzheimer's Disease Neuroimaging Initiative (\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ADNI\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       ") project, and the studies who made their data available in dbGaP</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "candidates = df_test_sent['sent'].to_list()\n",
    "\n",
    "for candidate in candidates:\n",
    "    label = set()\n",
    "    doc = custom_ner_model(candidate)\n",
    "    if len(doc.ents) > 0:\n",
    "        label.add(clean_text(doc.ents))\n",
    "        displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### has Indicator terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>section_title</th>\n",
       "      <th>sent</th>\n",
       "      <th>sent_clean</th>\n",
       "      <th>section_clean</th>\n",
       "      <th>freqData</th>\n",
       "      <th>freqEdu</th>\n",
       "      <th>freqSample</th>\n",
       "      <th>freqNational</th>\n",
       "      <th>freqSurvey</th>\n",
       "      <th>...</th>\n",
       "      <th>hasData</th>\n",
       "      <th>hasEdu</th>\n",
       "      <th>hasSample</th>\n",
       "      <th>hasNational</th>\n",
       "      <th>hasSurvey</th>\n",
       "      <th>hasPublic</th>\n",
       "      <th>hasAvail</th>\n",
       "      <th>hasNSF</th>\n",
       "      <th>hasGov</th>\n",
       "      <th>hasAccess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1755</th>\n",
       "      <td>2f392438-e215-4169-bebf-21ac4ff253e1</td>\n",
       "      <td>Indicator</td>\n",
       "      <td>Primary education refers to ISCED97 level 1</td>\n",
       "      <td>primary education refers to isced97 level 1</td>\n",
       "      <td>indicator</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2237</th>\n",
       "      <td>2f392438-e215-4169-bebf-21ac4ff253e1</td>\n",
       "      <td>How to read the charts</td>\n",
       "      <td>Although not included in the charts, postseco...</td>\n",
       "      <td>although not included in the charts postsecon...</td>\n",
       "      <td>how to read the charts</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1423</th>\n",
       "      <td>2f392438-e215-4169-bebf-21ac4ff253e1</td>\n",
       "      <td>Definitions and Methodology</td>\n",
       "      <td>94 and less than or equal to 409</td>\n",
       "      <td>94 and less than or equal to 409</td>\n",
       "      <td>definitions and methodology</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60</td>\n",
       "      <td>2</td>\n",
       "      <td>A small study in Houston found that African A...</td>\n",
       "      <td>a small study in houston found that african a...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1842</th>\n",
       "      <td>2f392438-e215-4169-bebf-21ac4ff253e1</td>\n",
       "      <td>Indicator 10</td>\n",
       "      <td>These range from level 1 to level 6, with lev...</td>\n",
       "      <td>these range from level 1 to level 6 with leve...</td>\n",
       "      <td>indicator 10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>2f392438-e215-4169-bebf-21ac4ff253e1</td>\n",
       "      <td>19</td>\n",
       "      <td>In the United States, the use for school achi...</td>\n",
       "      <td>in the united states the use for school achie...</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2208</th>\n",
       "      <td>2f392438-e215-4169-bebf-21ac4ff253e1</td>\n",
       "      <td>ISCED97 levels</td>\n",
       "      <td>The ISCED97 allows researchers to compile sta...</td>\n",
       "      <td>the isced97 allows researchers to compile sta...</td>\n",
       "      <td>isced97 levels</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>3f316b38-1a24-45a9-8d8c-4e05a42257c6</td>\n",
       "      <td>CONCLUSION</td>\n",
       "      <td>nccoastalatlas</td>\n",
       "      <td>nccoastalatlas</td>\n",
       "      <td>conclusion</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60</td>\n",
       "      <td>Primary data: customer intercept survey-data c...</td>\n",
       "      <td>The two eligibility criteria were that the st...</td>\n",
       "      <td>the two eligibility criteria were that the st...</td>\n",
       "      <td>primary data customer intercept survey data co...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>3f316b38-1a24-45a9-8d8c-4e05a42257c6</td>\n",
       "      <td>Storm Surge Vulnerability</td>\n",
       "      <td>This effort included a program to collect fir...</td>\n",
       "      <td>this effort included a program to collect fir...</td>\n",
       "      <td>storm surge vulnerability</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Id  \\\n",
       "1755  2f392438-e215-4169-bebf-21ac4ff253e1   \n",
       "2237  2f392438-e215-4169-bebf-21ac4ff253e1   \n",
       "1423  2f392438-e215-4169-bebf-21ac4ff253e1   \n",
       "103   8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60   \n",
       "1842  2f392438-e215-4169-bebf-21ac4ff253e1   \n",
       "2019  2f392438-e215-4169-bebf-21ac4ff253e1   \n",
       "2208  2f392438-e215-4169-bebf-21ac4ff253e1   \n",
       "859   3f316b38-1a24-45a9-8d8c-4e05a42257c6   \n",
       "116   8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60   \n",
       "627   3f316b38-1a24-45a9-8d8c-4e05a42257c6   \n",
       "\n",
       "                                          section_title  \\\n",
       "1755                                          Indicator   \n",
       "2237                             How to read the charts   \n",
       "1423                        Definitions and Methodology   \n",
       "103                                                   2   \n",
       "1842                                       Indicator 10   \n",
       "2019                                                 19   \n",
       "2208                                     ISCED97 levels   \n",
       "859                                          CONCLUSION   \n",
       "116   Primary data: customer intercept survey-data c...   \n",
       "627                           Storm Surge Vulnerability   \n",
       "\n",
       "                                                   sent  \\\n",
       "1755        Primary education refers to ISCED97 level 1   \n",
       "2237   Although not included in the charts, postseco...   \n",
       "1423                   94 and less than or equal to 409   \n",
       "103    A small study in Houston found that African A...   \n",
       "1842   These range from level 1 to level 6, with lev...   \n",
       "2019   In the United States, the use for school achi...   \n",
       "2208   The ISCED97 allows researchers to compile sta...   \n",
       "859                                      nccoastalatlas   \n",
       "116    The two eligibility criteria were that the st...   \n",
       "627    This effort included a program to collect fir...   \n",
       "\n",
       "                                             sent_clean  \\\n",
       "1755        primary education refers to isced97 level 1   \n",
       "2237   although not included in the charts postsecon...   \n",
       "1423                   94 and less than or equal to 409   \n",
       "103    a small study in houston found that african a...   \n",
       "1842   these range from level 1 to level 6 with leve...   \n",
       "2019   in the united states the use for school achie...   \n",
       "2208   the isced97 allows researchers to compile sta...   \n",
       "859                                      nccoastalatlas   \n",
       "116    the two eligibility criteria were that the st...   \n",
       "627    this effort included a program to collect fir...   \n",
       "\n",
       "                                          section_clean  freqData  freqEdu  \\\n",
       "1755                                          indicator         0        1   \n",
       "2237                             how to read the charts         0        0   \n",
       "1423                        definitions and methodology         0        0   \n",
       "103                                                   2         0        0   \n",
       "1842                                       indicator 10         0        0   \n",
       "2019                                                 19         1        0   \n",
       "2208                                     isced97 levels         0        1   \n",
       "859                                          conclusion         0        0   \n",
       "116   primary data customer intercept survey data co...         0        0   \n",
       "627                           storm surge vulnerability         1        0   \n",
       "\n",
       "      freqSample  freqNational  freqSurvey  ...  hasData  hasEdu  hasSample  \\\n",
       "1755           0             0           0  ...        0       1          0   \n",
       "2237           0             0           0  ...        0       0          0   \n",
       "1423           0             0           0  ...        0       0          0   \n",
       "103            0             0           0  ...        0       0          0   \n",
       "1842           0             0           0  ...        0       0          0   \n",
       "2019           0             0           0  ...        1       0          0   \n",
       "2208           0             1           0  ...        0       1          0   \n",
       "859            0             0           0  ...        0       0          0   \n",
       "116            0             0           0  ...        0       0          0   \n",
       "627            0             0           0  ...        1       0          0   \n",
       "\n",
       "      hasNational  hasSurvey  hasPublic  hasAvail  hasNSF  hasGov  hasAccess  \n",
       "1755            0          0          0         0       0       0          0  \n",
       "2237            0          0          0         0       0       0          0  \n",
       "1423            0          0          0         0       0       0          0  \n",
       "103             0          0          0         0       0       0          0  \n",
       "1842            0          0          0         0       0       0          0  \n",
       "2019            0          0          1         0       0       0          0  \n",
       "2208            1          0          0         0       0       0          0  \n",
       "859             0          0          0         0       0       0          0  \n",
       "116             0          0          0         0       0       0          0  \n",
       "627             0          0          0         0       0       0          0  \n",
       "\n",
       "[10 rows x 25 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_sent['freqData'] = df_test_sent['sent_clean'].str.count('data')\n",
    "df_test_sent['freqEdu'] = df_test_sent['sent_clean'].str.count('edu')\n",
    "df_test_sent['freqSample'] = df_test_sent['sent_clean'].str.count('sample')\n",
    "df_test_sent['freqNational'] = df_test_sent['sent_clean'].str.count('national')\n",
    "df_test_sent['freqSurvey'] = df_test_sent['sent_clean'].str.count('survey')\n",
    "df_test_sent['freqPublic'] = df_test_sent['sent_clean'].str.count('public')\n",
    "df_test_sent['freqAvail'] = df_test_sent['sent_clean'].str.count('avail')\n",
    "df_test_sent['freqNSF'] = df_test_sent['sent_clean'].str.count('nsf')\n",
    "df_test_sent['freqGov'] = df_test_sent['sent_clean'].str.count('gov')\n",
    "df_test_sent['freqAccess'] = df_test_sent['sent_clean'].str.count('access')\n",
    "\n",
    "df_test_sent['hasData'] = np.where(df_test_sent['sent_clean'].str.contains('data'), 1, 0)\n",
    "df_test_sent['hasEdu'] = np.where(df_test_sent['sent_clean'].str.contains('edu'), 1, 0)\n",
    "df_test_sent['hasSample'] = np.where(df_test_sent['sent_clean'].str.contains('sample'), 1, 0)\n",
    "df_test_sent['hasNational'] = np.where(df_test_sent['sent_clean'].str.contains('national'), 1, 0)\n",
    "df_test_sent['hasSurvey'] = np.where(df_test_sent['sent_clean'].str.contains('survey'), 1, 0)\n",
    "df_test_sent['hasPublic'] = np.where(df_test_sent['sent_clean'].str.contains('public'), 1, 0)\n",
    "df_test_sent['hasAvail'] = np.where(df_test_sent['sent_clean'].str.contains('survey'), 1, 0)\n",
    "df_test_sent['hasNSF'] = np.where(df_test_sent['sent_clean'].str.contains('nsf'), 1, 0)\n",
    "df_test_sent['hasGov'] = np.where(df_test_sent['sent_clean'].str.contains('gov'), 1, 0)\n",
    "df_test_sent['hasAccess'] = np.where(df_test_sent['sent_clean'].str.contains('access'), 1, 0)\n",
    "\n",
    "df_test_sent.sample(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### in Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>section_title</th>\n",
       "      <th>sent</th>\n",
       "      <th>sent_clean</th>\n",
       "      <th>section_clean</th>\n",
       "      <th>freqData</th>\n",
       "      <th>freqEdu</th>\n",
       "      <th>freqSample</th>\n",
       "      <th>freqNational</th>\n",
       "      <th>freqSurvey</th>\n",
       "      <th>...</th>\n",
       "      <th>inIntro</th>\n",
       "      <th>inDisc</th>\n",
       "      <th>inAbst</th>\n",
       "      <th>inResult</th>\n",
       "      <th>inConcl</th>\n",
       "      <th>inMethod</th>\n",
       "      <th>inBack</th>\n",
       "      <th>inData</th>\n",
       "      <th>inSumm</th>\n",
       "      <th>inAckno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60</td>\n",
       "      <td>What people buy</td>\n",
       "      <td>The CES analysis finds that a larger share of...</td>\n",
       "      <td>the ces analysis finds that a larger share of...</td>\n",
       "      <td>what people buy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1628</th>\n",
       "      <td>2f392438-e215-4169-bebf-21ac4ff253e1</td>\n",
       "      <td>Definitions and Methodology</td>\n",
       "      <td>eighth-graders whose principals reported inti...</td>\n",
       "      <td>eighth graders whose principals reported inti...</td>\n",
       "      <td>definitions and methodology</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2536</th>\n",
       "      <td>2100032a-7c33-4bff-97ef-690822c43466</td>\n",
       "      <td>Introduction</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>introduction</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762</th>\n",
       "      <td>2f392438-e215-4169-bebf-21ac4ff253e1</td>\n",
       "      <td>Indicator</td>\n",
       "      <td>dollars using 2006 national purchasing power ...</td>\n",
       "      <td>dollars using 2006 national purchasing power ...</td>\n",
       "      <td>indicator</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>2f392438-e215-4169-bebf-21ac4ff253e1</td>\n",
       "      <td>19</td>\n",
       "      <td>Principals of 15-yearold students were given ...</td>\n",
       "      <td>principals of 15 yearold students were given ...</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>3f316b38-1a24-45a9-8d8c-4e05a42257c6</td>\n",
       "      <td>Relative Vulnerability</td>\n",
       "      <td>As relative sea level reaches 1-2ft, the mars...</td>\n",
       "      <td>as relative sea level reaches 1 2ft the marsh...</td>\n",
       "      <td>relative vulnerability</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>2f392438-e215-4169-bebf-21ac4ff253e1</td>\n",
       "      <td>G-8 Countries</td>\n",
       "      <td>This was higher than in all other participati...</td>\n",
       "      <td>this was higher than in all other participati...</td>\n",
       "      <td>g 8 countries</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2324</th>\n",
       "      <td>2f392438-e215-4169-bebf-21ac4ff253e1</td>\n",
       "      <td>Postsecondary and tertiary:</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>postsecondary and tertiary</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>3f316b38-1a24-45a9-8d8c-4e05a42257c6</td>\n",
       "      <td>STUDY AREA</td>\n",
       "      <td>The boundary of the CAHA was used as the exten...</td>\n",
       "      <td>the boundary of the caha was used as the exten...</td>\n",
       "      <td>study area</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1631</th>\n",
       "      <td>2f392438-e215-4169-bebf-21ac4ff253e1</td>\n",
       "      <td>Definitions and Methodology</td>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "      <td>definitions and methodology</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Id                section_title  \\\n",
       "262   8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60              What people buy   \n",
       "1628  2f392438-e215-4169-bebf-21ac4ff253e1  Definitions and Methodology   \n",
       "2536  2100032a-7c33-4bff-97ef-690822c43466                 Introduction   \n",
       "1762  2f392438-e215-4169-bebf-21ac4ff253e1                    Indicator   \n",
       "2003  2f392438-e215-4169-bebf-21ac4ff253e1                           19   \n",
       "469   3f316b38-1a24-45a9-8d8c-4e05a42257c6       Relative Vulnerability   \n",
       "1795  2f392438-e215-4169-bebf-21ac4ff253e1                G-8 Countries   \n",
       "2324  2f392438-e215-4169-bebf-21ac4ff253e1  Postsecondary and tertiary:   \n",
       "404   3f316b38-1a24-45a9-8d8c-4e05a42257c6                   STUDY AREA   \n",
       "1631  2f392438-e215-4169-bebf-21ac4ff253e1  Definitions and Methodology   \n",
       "\n",
       "                                                   sent  \\\n",
       "262    The CES analysis finds that a larger share of...   \n",
       "1628   eighth-graders whose principals reported inti...   \n",
       "2536                                                      \n",
       "1762   dollars using 2006 national purchasing power ...   \n",
       "2003   Principals of 15-yearold students were given ...   \n",
       "469    As relative sea level reaches 1-2ft, the mars...   \n",
       "1795   This was higher than in all other participati...   \n",
       "2324                                                      \n",
       "404   The boundary of the CAHA was used as the exten...   \n",
       "1631                                                  e   \n",
       "\n",
       "                                             sent_clean  \\\n",
       "262    the ces analysis finds that a larger share of...   \n",
       "1628   eighth graders whose principals reported inti...   \n",
       "2536                                                      \n",
       "1762   dollars using 2006 national purchasing power ...   \n",
       "2003   principals of 15 yearold students were given ...   \n",
       "469    as relative sea level reaches 1 2ft the marsh...   \n",
       "1795   this was higher than in all other participati...   \n",
       "2324                                                      \n",
       "404   the boundary of the caha was used as the exten...   \n",
       "1631                                                  e   \n",
       "\n",
       "                    section_clean  freqData  freqEdu  freqSample  \\\n",
       "262               what people buy         0        0           0   \n",
       "1628  definitions and methodology         0        0           0   \n",
       "2536                 introduction         0        0           0   \n",
       "1762                    indicator         1        0           0   \n",
       "2003                           19         1        0           0   \n",
       "469        relative vulnerability         0        0           0   \n",
       "1795                g 8 countries         0        0           0   \n",
       "2324  postsecondary and tertiary          0        0           0   \n",
       "404                    study area         0        0           0   \n",
       "1631  definitions and methodology         0        0           0   \n",
       "\n",
       "      freqNational  freqSurvey  ...  inIntro  inDisc  inAbst  inResult  \\\n",
       "262              0           0  ...        0       0       0         0   \n",
       "1628             0           0  ...        0       0       0         0   \n",
       "2536             0           0  ...        1       0       0         0   \n",
       "1762             1           0  ...        0       0       0         0   \n",
       "2003             0           0  ...        0       0       0         0   \n",
       "469              0           0  ...        0       0       0         0   \n",
       "1795             0           0  ...        0       0       0         0   \n",
       "2324             0           0  ...        0       0       0         0   \n",
       "404              0           0  ...        0       0       0         0   \n",
       "1631             0           0  ...        0       0       0         0   \n",
       "\n",
       "      inConcl  inMethod  inBack  inData  inSumm  inAckno  \n",
       "262         0         0       0       0       0        0  \n",
       "1628        0         1       0       0       0        0  \n",
       "2536        0         0       0       0       0        0  \n",
       "1762        0         0       0       0       0        0  \n",
       "2003        0         0       0       0       0        0  \n",
       "469         0         0       0       0       0        0  \n",
       "1795        0         0       0       0       0        0  \n",
       "2324        0         0       0       0       0        0  \n",
       "404         0         0       0       0       0        0  \n",
       "1631        0         1       0       0       0        0  \n",
       "\n",
       "[10 rows x 35 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_sent['inIntro'] = np.where(df_test_sent['section_clean'].str.contains('intro'), 1, 0)\n",
    "df_test_sent['inDisc'] = np.where(df_test_sent['section_clean'].str.contains('discus'), 1, 0)\n",
    "df_test_sent['inAbst'] = np.where(df_test_sent['section_clean'].str.contains('abstr'), 1, 0)\n",
    "df_test_sent['inResult'] = np.where(df_test_sent['section_clean'].str.contains('resul'), 1, 0)\n",
    "df_test_sent['inConcl'] = np.where(df_test_sent['section_clean'].str.contains('conclu'), 1, 0)\n",
    "df_test_sent['inMethod'] = np.where(df_test_sent['section_clean'].str.contains('meth'), 1, 0)\n",
    "df_test_sent['inBack'] = np.where(df_test_sent['section_clean'].str.contains('back'), 1, 0)\n",
    "df_test_sent['inData'] = np.where(df_test_sent['section_clean'].str.contains('data'), 1, 0)\n",
    "df_test_sent['inSumm'] = np.where(df_test_sent['section_clean'].str.contains('summ'), 1, 0)\n",
    "df_test_sent['inAckno'] = np.where(df_test_sent['section_clean'].str.contains('acknowl'), 1, 0)\n",
    "\n",
    "df_test_sent.sample(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## has Acronyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2054\n",
       "1     668\n",
       "Name: hasAcronym, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_sent['hasAcronym'] = df_test_sent['sent'].apply(find_acronyms)\n",
    "df_test_sent['hasAcronym'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 7, 3, 4, 5, 8, 6])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_sent['freqAcronym'] = df_test_sent['sent'].apply(count_acronyms)\n",
    "df_test_sent['freqAcronym'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## has Titles\n",
    "Check if a sentence has a dataset title from Data.gov or ICPSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.24 s, sys: 0 ns, total: 5.24 s\n",
      "Wall time: 5.26 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    2716\n",
       "1       6\n",
       "Name: hasICPSRTitle, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icpsr = pd.read_csv(DATA_DIR + 'labels/icpsr_studies.csv')\n",
    "icpsr_labels = icpsr['NAME'].apply(clean_text).str.replace('\\d+', '')\n",
    "\n",
    "%time df_test_sent['hasICPSRTitle'] = df_test_sent['sent_clean'].apply(lambda x: any([k in x for k in icpsr_labels]))\n",
    "df_test_sent['hasICPSRTitle'] = df_test_sent['hasICPSRTitle'].astype('category').cat.codes\n",
    "\n",
    "df_test_sent['hasICPSRTitle'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.05 s, sys: 0 ns, total: 1.05 s\n",
      "Wall time: 1.05 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    2707\n",
       "1      15\n",
       "Name: hasDATAGOVTitle, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datagov = pd.read_csv(DATA_DIR + 'labels/kaggle_data_800.csv')\n",
    "datagov_labels = datagov['title'].apply(clean_text).str.replace('\\d+', '')\n",
    "\n",
    "%time df_test_sent['hasDATAGOVTitle'] = df_test_sent['sent_clean'].apply(lambda x: any([k in x for k in datagov_labels]))\n",
    "df_test_sent['hasDATAGOVTitle'] = df_test_sent['hasDATAGOVTitle'].astype('category').cat.codes\n",
    "\n",
    "df_test_sent['hasDATAGOVTitle'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2722 entries, 0 to 2721\n",
      "Data columns (total 39 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Id               2722 non-null   object\n",
      " 1   section_title    2722 non-null   object\n",
      " 2   sent             2722 non-null   object\n",
      " 3   sent_clean       2722 non-null   object\n",
      " 4   section_clean    2722 non-null   object\n",
      " 5   freqData         2722 non-null   int64 \n",
      " 6   freqEdu          2722 non-null   int64 \n",
      " 7   freqSample       2722 non-null   int64 \n",
      " 8   freqNational     2722 non-null   int64 \n",
      " 9   freqSurvey       2722 non-null   int64 \n",
      " 10  freqPublic       2722 non-null   int64 \n",
      " 11  freqAvail        2722 non-null   int64 \n",
      " 12  freqNSF          2722 non-null   int64 \n",
      " 13  freqGov          2722 non-null   int64 \n",
      " 14  freqAccess       2722 non-null   int64 \n",
      " 15  hasData          2722 non-null   int64 \n",
      " 16  hasEdu           2722 non-null   int64 \n",
      " 17  hasSample        2722 non-null   int64 \n",
      " 18  hasNational      2722 non-null   int64 \n",
      " 19  hasSurvey        2722 non-null   int64 \n",
      " 20  hasPublic        2722 non-null   int64 \n",
      " 21  hasAvail         2722 non-null   int64 \n",
      " 22  hasNSF           2722 non-null   int64 \n",
      " 23  hasGov           2722 non-null   int64 \n",
      " 24  hasAccess        2722 non-null   int64 \n",
      " 25  inIntro          2722 non-null   int64 \n",
      " 26  inDisc           2722 non-null   int64 \n",
      " 27  inAbst           2722 non-null   int64 \n",
      " 28  inResult         2722 non-null   int64 \n",
      " 29  inConcl          2722 non-null   int64 \n",
      " 30  inMethod         2722 non-null   int64 \n",
      " 31  inBack           2722 non-null   int64 \n",
      " 32  inData           2722 non-null   int64 \n",
      " 33  inSumm           2722 non-null   int64 \n",
      " 34  inAckno          2722 non-null   int64 \n",
      " 35  hasAcronym       2722 non-null   int64 \n",
      " 36  freqAcronym      2722 non-null   int64 \n",
      " 37  hasICPSRTitle    2722 non-null   int8  \n",
      " 38  hasDATAGOVTitle  2722 non-null   int8  \n",
      "dtypes: int64(32), int8(2), object(5)\n",
      "memory usage: 792.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test_sent.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test_sent.to_csv(DATA_DIR + 'test_sents_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>sent</th>\n",
       "      <th>freqData</th>\n",
       "      <th>freqEdu</th>\n",
       "      <th>freqSample</th>\n",
       "      <th>freqNational</th>\n",
       "      <th>freqSurvey</th>\n",
       "      <th>freqPublic</th>\n",
       "      <th>freqAvail</th>\n",
       "      <th>freqNSF</th>\n",
       "      <th>...</th>\n",
       "      <th>inConcl</th>\n",
       "      <th>inMethod</th>\n",
       "      <th>inBack</th>\n",
       "      <th>inData</th>\n",
       "      <th>inSumm</th>\n",
       "      <th>inAckno</th>\n",
       "      <th>hasAcronym</th>\n",
       "      <th>freqAcronym</th>\n",
       "      <th>hasICPSRTitle</th>\n",
       "      <th>hasDATAGOVTitle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60</td>\n",
       "      <td>A significant body of research has been conduc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60</td>\n",
       "      <td>Even though lowincome (LI) households' choice...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60</td>\n",
       "      <td>Findings on purchasing patterns of LI househo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60</td>\n",
       "      <td>Understanding the specific factors related to...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60</td>\n",
       "      <td>This study contributes to the literature by e...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Id  \\\n",
       "0  8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60   \n",
       "1  8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60   \n",
       "2  8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60   \n",
       "3  8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60   \n",
       "4  8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60   \n",
       "\n",
       "                                                sent  freqData  freqEdu  \\\n",
       "0  A significant body of research has been conduc...         0        0   \n",
       "1   Even though lowincome (LI) households' choice...         0        0   \n",
       "2   Findings on purchasing patterns of LI househo...         0        0   \n",
       "3   Understanding the specific factors related to...         0        0   \n",
       "4   This study contributes to the literature by e...         1        0   \n",
       "\n",
       "   freqSample  freqNational  freqSurvey  freqPublic  freqAvail  freqNSF  ...  \\\n",
       "0           0             0           0           0          0        0  ...   \n",
       "1           0             0           0           0          0        0  ...   \n",
       "2           0             0           0           0          0        0  ...   \n",
       "3           0             0           0           0          0        0  ...   \n",
       "4           0             0           0           0          0        0  ...   \n",
       "\n",
       "   inConcl  inMethod  inBack  inData  inSumm  inAckno  hasAcronym  \\\n",
       "0        0         0       0       0       0        0           0   \n",
       "1        0         0       0       0       0        0           1   \n",
       "2        0         0       0       0       0        0           1   \n",
       "3        0         0       0       0       0        0           0   \n",
       "4        0         0       0       0       0        0           0   \n",
       "\n",
       "   freqAcronym  hasICPSRTitle  hasDATAGOVTitle  \n",
       "0            0              0                0  \n",
       "1            2              0                0  \n",
       "2            1              0                0  \n",
       "3            0              0                0  \n",
       "4            0              0                0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_sent = df_test_sent.drop(columns=['section_title', \n",
    "                                          'sent_clean', \n",
    "                                          'section_clean'])\n",
    "\n",
    "df_test_sent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2722, 36)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_sent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2722, 34)\n"
     ]
    }
   ],
   "source": [
    "X_new = df_test_sent.iloc[:, 2:]\n",
    "\n",
    "print(X_new.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier\n",
    "Pass tokenized test sentences to the classifier and keep predicted sentences  with prob > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', n_jobs=2, random_state=42)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = DATA_DIR + \"classifier\"\n",
    "\n",
    "pkl_filename = model_path+\"/RF_balanced_model.pkl\"\n",
    "\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    best_model = pickle.load(file)\n",
    "\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the trained classifier to the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.6 ms, sys: 4.08 ms, total: 44.7 ms\n",
      "Wall time: 30.3 ms\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "%time predict = best_model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append the predicted probability of 0, 1 to test dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>sent</th>\n",
       "      <th>freqData</th>\n",
       "      <th>freqEdu</th>\n",
       "      <th>freqSample</th>\n",
       "      <th>freqNational</th>\n",
       "      <th>freqSurvey</th>\n",
       "      <th>freqPublic</th>\n",
       "      <th>freqAvail</th>\n",
       "      <th>freqNSF</th>\n",
       "      <th>...</th>\n",
       "      <th>inBack</th>\n",
       "      <th>inData</th>\n",
       "      <th>inSumm</th>\n",
       "      <th>inAckno</th>\n",
       "      <th>hasAcronym</th>\n",
       "      <th>freqAcronym</th>\n",
       "      <th>hasICPSRTitle</th>\n",
       "      <th>hasDATAGOVTitle</th>\n",
       "      <th>prob_0</th>\n",
       "      <th>prob_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60</td>\n",
       "      <td>A significant body of research has been conduc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997355</td>\n",
       "      <td>0.002645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60</td>\n",
       "      <td>Even though lowincome (LI) households' choice...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.941944</td>\n",
       "      <td>0.058056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60</td>\n",
       "      <td>Findings on purchasing patterns of LI househo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.963614</td>\n",
       "      <td>0.036386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60</td>\n",
       "      <td>Understanding the specific factors related to...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997355</td>\n",
       "      <td>0.002645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60</td>\n",
       "      <td>This study contributes to the literature by e...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2717</th>\n",
       "      <td>2100032a-7c33-4bff-97ef-690822c43466</td>\n",
       "      <td>\\nTrampush et al</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999807</td>\n",
       "      <td>0.000193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2718</th>\n",
       "      <td>2100032a-7c33-4bff-97ef-690822c43466</td>\n",
       "      <td>Page 19   Table 3 Meta-analytic results of th...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999807</td>\n",
       "      <td>0.000193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2719</th>\n",
       "      <td>2100032a-7c33-4bff-97ef-690822c43466</td>\n",
       "      <td>1 associated with educational attainment in CO...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2720</th>\n",
       "      <td>2100032a-7c33-4bff-97ef-690822c43466</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999807</td>\n",
       "      <td>0.000193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2721</th>\n",
       "      <td>2100032a-7c33-4bff-97ef-690822c43466</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999807</td>\n",
       "      <td>0.000193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2722 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Id  \\\n",
       "0     8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60   \n",
       "1     8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60   \n",
       "2     8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60   \n",
       "3     8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60   \n",
       "4     8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60   \n",
       "...                                    ...   \n",
       "2717  2100032a-7c33-4bff-97ef-690822c43466   \n",
       "2718  2100032a-7c33-4bff-97ef-690822c43466   \n",
       "2719  2100032a-7c33-4bff-97ef-690822c43466   \n",
       "2720  2100032a-7c33-4bff-97ef-690822c43466   \n",
       "2721  2100032a-7c33-4bff-97ef-690822c43466   \n",
       "\n",
       "                                                   sent  freqData  freqEdu  \\\n",
       "0     A significant body of research has been conduc...         0        0   \n",
       "1      Even though lowincome (LI) households' choice...         0        0   \n",
       "2      Findings on purchasing patterns of LI househo...         0        0   \n",
       "3      Understanding the specific factors related to...         0        0   \n",
       "4      This study contributes to the literature by e...         1        0   \n",
       "...                                                 ...       ...      ...   \n",
       "2717                                   \\nTrampush et al         0        0   \n",
       "2718   Page 19   Table 3 Meta-analytic results of th...         0        0   \n",
       "2719  1 associated with educational attainment in CO...         0        1   \n",
       "2720                                                            0        0   \n",
       "2721                                                            0        0   \n",
       "\n",
       "      freqSample  freqNational  freqSurvey  freqPublic  freqAvail  freqNSF  \\\n",
       "0              0             0           0           0          0        0   \n",
       "1              0             0           0           0          0        0   \n",
       "2              0             0           0           0          0        0   \n",
       "3              0             0           0           0          0        0   \n",
       "4              0             0           0           0          0        0   \n",
       "...          ...           ...         ...         ...        ...      ...   \n",
       "2717           0             0           0           0          0        0   \n",
       "2718           0             0           0           0          0        0   \n",
       "2719           0             0           0           0          0        0   \n",
       "2720           0             0           0           0          0        0   \n",
       "2721           0             0           0           0          0        0   \n",
       "\n",
       "      ...  inBack  inData  inSumm  inAckno  hasAcronym  freqAcronym  \\\n",
       "0     ...       0       0       0        0           0            0   \n",
       "1     ...       0       0       0        0           1            2   \n",
       "2     ...       0       0       0        0           1            1   \n",
       "3     ...       0       0       0        0           0            0   \n",
       "4     ...       0       0       0        0           0            0   \n",
       "...   ...     ...     ...     ...      ...         ...          ...   \n",
       "2717  ...       0       0       0        0           0            0   \n",
       "2718  ...       0       0       0        0           0            0   \n",
       "2719  ...       0       0       0        0           1            6   \n",
       "2720  ...       0       0       0        0           0            0   \n",
       "2721  ...       0       0       0        0           0            0   \n",
       "\n",
       "      hasICPSRTitle  hasDATAGOVTitle    prob_0    prob_1  \n",
       "0                 0                0  0.997355  0.002645  \n",
       "1                 0                0  0.941944  0.058056  \n",
       "2                 0                0  0.963614  0.036386  \n",
       "3                 0                0  0.997355  0.002645  \n",
       "4                 0                0  1.000000  0.000000  \n",
       "...             ...              ...       ...       ...  \n",
       "2717              0                0  0.999807  0.000193  \n",
       "2718              0                0  0.999807  0.000193  \n",
       "2719              0                0  1.000000  0.000000  \n",
       "2720              0                0  0.999807  0.000193  \n",
       "2721              0                0  0.999807  0.000193  \n",
       "\n",
       "[2722 rows x 38 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = best_model.predict_proba(X_new)\n",
    "df_test_sent['prob_0'] = prob[:,0] \n",
    "df_test_sent['prob_1'] = prob[:,1]\n",
    "\n",
    "df_test_sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the dataframe to extract high likelihood sentences by keeping rows with `prob_1` >= 0.1\n",
    "* Try different thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_candidates = df_test_sent.query('prob_1 >= 0.01')\n",
    "\n",
    "# for sent in df_candidates.sent:\n",
    "#     print(sent, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What percent of sentences have a higher likelihood of being citances?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.491550330639235\n"
     ]
    }
   ],
   "source": [
    "print((len(df_candidates)/len(df_test_sent))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER\n",
    "Apply custom model to candidate sentences only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> Participants' county of residence was linked with the USDA (2013) \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Rural-Urban Continuum Codes\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       " (RUCCs) (United States Department of Agriculture, 2013) to determine if the household was located in an urban or rural area</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> Prior directly relevant assessments of sea level rise include Titus and Wang (2008) and the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    NC Sea Level Rise Risk Management Study\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       " (SLRRMS)</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> The \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    SLOSH MEOWs\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       " are a composite product that is produced from thousands of model runs with the same category, forward speed, storm trajectory, and initial tide level</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> The \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    SLOSH MOMs\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       " provide a worst case scenario product as they are compiled based on the maximum storm surge height for all hurricanes of a given category regardless of forward speed, storm trajectory, or landfall location</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> The adopted methodology incorporates techniques adapted from the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    NOAA Storm Surge\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       " Inundation Mapping guide, NC SLRRMS, and several projects conducted at East Carolina University</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> The principal data include: 1) the newest NOAA National Hurricane Center (NHC) Sea, Lake, and Overland Surges from Hurricanes (\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    SLOSH) basin models\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       "; 2) Historic Districts and specific historic structure building  Table 3</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">) Storm surge modeling data was obtained from the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    SLOSH display\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       " program and used to map the extent and depth of inundation resulting from various storm scenarios ( Figure 6)</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> The \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    SLOSH model\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       " was developed by the National Weather Service's NHC to estimate storm surge from hurricanes using storm properties (e</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> The newest available \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    SLOSH grids\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       " for the Hatteras area were obtained and coregistered to the NC LiDAR, building footprints, and other GIS datasets</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Mapping the storm surge inundation involved exporting the data from the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    SLOSH display\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       " program that contained the height of the storm surge that was modeled using the MOMs approach for the Cape Hatteras/Pamlico Sound (ht3) Basin for each category storm that occurred during high tide ( Figure 7)</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> The \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    SLOSH display\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       " program exports the data as a shapefile in WGS84</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> Additional fields were added to each attribute table, and the appropriate value was added to the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    SLOSH output\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       " to simulate the height of the storm surge that would occur under different sea level rise scenarios of 20, 40, 70, 100, and 140 cm</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> The Spline interpolation method was used to create a water surface based on the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    SLOSH point\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       " attributes at a 5-m resolution</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> Across much of the region today, a category 2 storm surge of a nearby landfalling hurricane is required to inundation most areas of the Outer Banks in our modeling with \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    SLOSH and\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       " LiDAR DEMs</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">This section presents results of site level vulnerability assessment, focusing on the historic structures and landmarks for each district and their elevation relationship between finished first floors (FFE) and the height of \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    SLOSH storm\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       " surge models with sea level rise</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> Figure 18 portrays some of the underlying data, a \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    SLOSH inundation grid\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       " superimposed on the LiDAR DEM with building centroids and footprints (inset A and B)</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> Columns reference the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    SLOSH Safir\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       "-Simpson categories, and each table represents a distinct SLR scenario</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> The FFEs of the structures are higher than the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    SLOSH MOM\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       " surges for most category 1 storms (of course, non-inclusive of superimposed wave action</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> The USGS has developed the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Coastal Change Hazards Portal\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       ", which provides interactive web mapping capabilities and downloadable data layers to analyze coastal change science along our Nation's coast</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> We were fortuitous with the release of a new \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    SLOSH grid\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       " for the Hatteras region by the NWS National Hurricane Center, allowing some improvement to the downscaling of MOM inundation maps</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> Static SLR and \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    SLOSH grids\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       ", LiDAR DEMs, and shoreline data, for instance, could be assimilated in models such as the Sea Level Affecting Marshes Model (SLAMM) to evaluate marsh fragmentation, loss, or migration up elevation</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> Comparative Indicators of Education in the United States and Other G-8 Countries: 2009 draws on the most current information about education from four primary sources: the Indicators of National Education Systems (INES) at the Organization for Economic Cooperation and Development (OECD); the Progress in International reading Literacy Study (PIrLS); the Program for International Student Assessment (PISA); and the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Trends in International Mathematics and Science Study\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       " (TIMSS)</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> these projects include the Indicators of national Education Systems (InES) at the organization for Economic cooperation and development (oEcd); the Progress in International reading Literacy Study (PIrLS); the Program for International Student Assessment (PISA); and the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    trends in International Mathematics and Science Study\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       " (tIMSS)</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> Census Bureau, the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    NCES Common Core of Data\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       " (CCD), the NCES Integrated Postsecondary Education Data System (IPEDS), and the NCES Schools and Staffing Survey (SASS)</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> These benchmarks are identical to the cutpoints used for the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Trends in International Mathematics and Science Study\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       " (TIMSS)</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> Using eighth-grade data from the 2007 \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Trends in International Mathematics and Science Study\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       " (TIMSS 2007), this indicator presents school principals' reports of both the incidence of behaviors that threaten a safe and orderly environment and their perceptions of these behaviors as a &quot;serious&quot; problem</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">This indicator presents the percentages of fourth-and eighthgraders reaching the four international benchmarks in science (low, intermediate, high, and advanced) in the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Trends in International Mathematics and Science Study\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       " (TIMSS) in 2007</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">   This indicator addresses differences by sex in science achievement among fourth-and eighth-grade students in the G-8 countries that participated in the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Trends in International Mathematics and Science Study\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       " (TIMSS) in 2007</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> Finally, several publicly available datasets were included; we kindly thank the investigative teams and staffs of the Pediatric Imaging, Neurocognition, and Genetics (PING) study, the Alzheimer's Disease Neuroimaging Initiative (\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ADNI\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATASET</span>\n",
       "</mark>\n",
       ") project, and the studies who made their data available in dbGaP</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "candidates = df_candidates['sent'].to_list()\n",
    "\n",
    "for candidate in candidates:\n",
    "    label = set()\n",
    "    doc = custom_ner_model(candidate)\n",
    "    if len(doc.ents) > 0:\n",
    "        label.add(clean_text(doc.ents))\n",
    "        displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " adni  \n",
      "\n",
      " nces common core of data | trends in international mathematics and science study  \n",
      "\n",
      " coastal change hazards portal | nc sea level rise risk management study | noaa storm surge | slosh and | slosh basin models | slosh display | slosh grid | slosh grids | slosh inundation grid | slosh meows | slosh model | slosh mom | slosh moms | slosh output | slosh point | slosh safir | slosh storm  \n",
      "\n",
      " rural urban continuum codes  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "\n",
    "for index in submission_df.Id:\n",
    "    publication_text = df_candidates[df_candidates['Id'] == index].sent\n",
    "    label = set()\n",
    "    for candidate in publication_text:\n",
    "        doc = custom_ner_model(candidate)\n",
    "        if len(doc.ents) > 0:\n",
    "            label.add(clean_text(doc.ents))\n",
    "    label_list = sorted(list(label))\n",
    "    result.append('|'.join(label_list))\n",
    "\n",
    "for hit in result:\n",
    "    print(hit, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2100032a-7c33-4bff-97ef-690822c43466</td>\n",
       "      <td>adni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2f392438-e215-4169-bebf-21ac4ff253e1</td>\n",
       "      <td>nces common core of data | trends in internat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3f316b38-1a24-45a9-8d8c-4e05a42257c6</td>\n",
       "      <td>coastal change hazards portal | nc sea level ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60</td>\n",
       "      <td>rural urban continuum codes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Id  \\\n",
       "0  2100032a-7c33-4bff-97ef-690822c43466   \n",
       "1  2f392438-e215-4169-bebf-21ac4ff253e1   \n",
       "2  3f316b38-1a24-45a9-8d8c-4e05a42257c6   \n",
       "3  8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60   \n",
       "\n",
       "                                    PredictionString  \n",
       "0                                              adni   \n",
       "1   nces common core of data | trends in internat...  \n",
       "2   coastal change hazards portal | nc sea level ...  \n",
       "3                       rural urban continuum codes   "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df['PredictionString'] = result\n",
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
