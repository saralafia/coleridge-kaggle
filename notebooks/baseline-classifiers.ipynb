{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline classifiers\n",
    "\n",
    "Pipeline for predicting classes of dataset references\n",
    "\n",
    "Author: Jinseok Kim\n",
    "\n",
    "Editor: Sara Lafia (adapting for competition)\n",
    "\n",
    "04/23/2021\n",
    "\n",
    "< To Do >\n",
    "- [x] drop datasets with less than (5) citances\n",
    "- [x] use citances (sentences containing citations) rather than labels for training/testing \n",
    "- [ ] add dummy model for comparison\n",
    "- [ ] add pipeline, gridsearch function for comparing and selecting best models\n",
    "\n",
    "< NOTE >\n",
    "1. Procedure: import, preprocessing, training, predicting (four algorithms), model evaluation\n",
    "2. Probability prediction output: each prediction produces a probability score between 0 and 1  \n",
    "3. Data splitting before training: 80% training and 20% test data   \n",
    "5. Class imbalance >> Apply sampling method (undersampling/oversampling) \n",
    "   Install 'imbalanced-learn' library: type the following code in command line interface (cmd)  \n",
    "   A. Check if pip is already installed: pip --version  or pip3 --version\n",
    "   B. Install the package: pip installl imbalanced-learn or pip3 install imbalanced-learn  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import nltk\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(txt):\n",
    "    \"\"\"\n",
    "    Convert to lowercase, remove special characters, and punctuation.\n",
    "    \"\"\"\n",
    "    return re.sub('[^A-Za-z0-9]+', ' ', str(txt).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/'\n",
    "DATA_DIR = '/nfs/turbo/hrg/coleridge/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "Load tokenized training sentences generated in `prep-sentences` notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sw/arcts/centos7/python3.8-anaconda/2020.07/lib/python3.8/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1116344 entries, 195 to 6788807\n",
      "Data columns (total 18 columns):\n",
      " #   Column         Non-Null Count    Dtype \n",
      "---  ------         --------------    ----- \n",
      " 0   Id             1116344 non-null  object\n",
      " 1   dataset_label  1116344 non-null  object\n",
      " 2   section_title  1116344 non-null  object\n",
      " 3   sent           1116344 non-null  object\n",
      " 4   match          1116344 non-null  bool  \n",
      " 5   sent_clean     1116344 non-null  object\n",
      " 6   clean_section  1116344 non-null  object\n",
      " 7   indicator      422515 non-null   object\n",
      " 8   hasData        1116344 non-null  int64 \n",
      " 9   hasEdu         1116344 non-null  int64 \n",
      " 10  hasSample      1116344 non-null  int64 \n",
      " 11  hasNational    1116344 non-null  int64 \n",
      " 12  hasSurvey      1116344 non-null  int64 \n",
      " 13  inIntro        1116344 non-null  int64 \n",
      " 14  inMethod       1116344 non-null  int64 \n",
      " 15  inLimit        1116344 non-null  int64 \n",
      " 16  inConcl        1116344 non-null  int64 \n",
      " 17  inAckno        1116344 non-null  int64 \n",
      "dtypes: bool(1), int64(10), object(7)\n",
      "memory usage: 154.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_DIR+'train_sentences_all.csv', index_col=0)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1101069\n",
       "1      15275\n",
       "Name: isMatch, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['isMatch'] = df['match'].astype('category').cat.codes\n",
    "\n",
    "df = df.drop(columns=['dataset_label', \n",
    "                      'section_title', \n",
    "                      'match',\n",
    "                      'sent_clean', \n",
    "                      'clean_section', \n",
    "                      'indicator'])\n",
    "\n",
    "df['isMatch'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>sent</th>\n",
       "      <th>hasData</th>\n",
       "      <th>hasEdu</th>\n",
       "      <th>hasSample</th>\n",
       "      <th>hasNational</th>\n",
       "      <th>hasSurvey</th>\n",
       "      <th>inIntro</th>\n",
       "      <th>inMethod</th>\n",
       "      <th>inLimit</th>\n",
       "      <th>inConcl</th>\n",
       "      <th>inAckno</th>\n",
       "      <th>isMatch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>2f26f645-3dec-485d-b68d-f013c9e05e60</td>\n",
       "      <td>Overall, the results presented in this Issue B...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>2f26f645-3dec-485d-b68d-f013c9e05e60</td>\n",
       "      <td>These estimates offer an early look at the pos...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>2f26f645-3dec-485d-b68d-f013c9e05e60</td>\n",
       "      <td>Some dropouts who were enrolled in a postsecon...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>2f26f645-3dec-485d-b68d-f013c9e05e60</td>\n",
       "      <td>Future research could use NELS respondents' po...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>2f26f645-3dec-485d-b68d-f013c9e05e60</td>\n",
       "      <td>Table 2 .</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Id  \\\n",
       "195  2f26f645-3dec-485d-b68d-f013c9e05e60   \n",
       "196  2f26f645-3dec-485d-b68d-f013c9e05e60   \n",
       "197  2f26f645-3dec-485d-b68d-f013c9e05e60   \n",
       "198  2f26f645-3dec-485d-b68d-f013c9e05e60   \n",
       "199  2f26f645-3dec-485d-b68d-f013c9e05e60   \n",
       "\n",
       "                                                  sent  hasData  hasEdu  \\\n",
       "195  Overall, the results presented in this Issue B...        0       0   \n",
       "196  These estimates offer an early look at the pos...        0       0   \n",
       "197  Some dropouts who were enrolled in a postsecon...        0       1   \n",
       "198  Future research could use NELS respondents' po...        0       0   \n",
       "199                                          Table 2 .        0       0   \n",
       "\n",
       "     hasSample  hasNational  hasSurvey  inIntro  inMethod  inLimit  inConcl  \\\n",
       "195          0            0          0        0         0        0        0   \n",
       "196          0            0          0        0         0        0        0   \n",
       "197          0            0          0        0         0        0        0   \n",
       "198          0            0          0        0         0        0        0   \n",
       "199          0            0          0        0         0        0        0   \n",
       "\n",
       "     inAckno  isMatch  \n",
       "195        0        0  \n",
       "196        0        0  \n",
       "197        0        0  \n",
       "198        0        0  \n",
       "199        0        0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    \"\"\"\n",
    "    Read in input file and load data\n",
    "    \n",
    "    filename: csv file\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Load input file\n",
    "    df = pd.read_csv(filename, encoding='utf-8') # if this produces encoding errors, use 'encoding='iso-8859-1'\n",
    "\n",
    "    print(\"Total No of Rows: \", df.shape[0])\n",
    "    print(\"Total No of Columns: \", df.shape[1])\n",
    "    \n",
    "    print('\\nTraining & Test Size(row, colum):')\n",
    "    df.iloc[:, -1].value_counts()\n",
    "\n",
    "    # Split data into training and test (Test size: 0.2, stratify turned on)\n",
    "    X, y = df.iloc[:, :-1], df.iloc[:, -1]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "    print('X_train: {}\\nX_test: {}\\ny_train: {}\\ny_test: {}'.format(X_train.shape, X_test.shape, y_train.shape, y_test.shape))\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(X_train, y_train, sampling=0, sample_method='over'):\n",
    "    \n",
    "    from imblearn.over_sampling import RandomOverSampler\n",
    "    from imblearn.under_sampling import RandomUnderSampler\n",
    "    \n",
    "    if sampling:\n",
    "        # select a sampling method\n",
    "        if sample_method == 'over':\n",
    "            oversample = RandomOverSampler(random_state=42)\n",
    "            X_over, y_over = oversample.fit_resample(X_train, y_train)\n",
    "            print('\\nOversampled Data (class, Rows):\\n{}'.format(y_over.value_counts()))\n",
    "            X_train_sam, y_train_sam = X_over, y_over\n",
    "            \n",
    "        elif sample_method == 'under':\n",
    "            undersample = RandomUnderSampler(random_state=42)\n",
    "            X_under, y_under = undersample.fit_resample(X_train, y_train)\n",
    "            print('\\nUndersampled Data (class,Rows):\\n{}'.format(y_under.value_counts()))\n",
    "            X_train_sam, y_train_sam = X_under, y_under\n",
    "    else:\n",
    "        X_train_sam, y_train_sam = X_train, y_train      \n",
    "        print('\\nNo Sampling Performed\\n')\n",
    "    \n",
    "    return X_train_sam, y_train_sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X_data_raw):\n",
    "    \n",
    "    \"\"\"\n",
    "       Preprocess data with lowercase conversion, punctuation removal, stop-word removal, tokenization, stemming, and joining\n",
    "       \n",
    "       X_data_raw: X data in dataframe\n",
    "       \n",
    "    \"\"\"\n",
    "    X_data=X_data_raw.iloc[:, 1]\n",
    "    \n",
    "    # 1 convert all characters to lowercase\n",
    "    X_data = X_data.map(lambda x: str(x).lower())\n",
    "     \n",
    "    # 2. remove non-alphabetical characters\n",
    "    X_data = X_data.str.replace(\"[^a-zA-Z]\", \" \", regex=True)\n",
    "    \n",
    "    # remove stopwords in English\n",
    "    stop_english = stopwords.words('english')\n",
    "    X_data = X_data.apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_english)]))\n",
    "    \n",
    "    # remove words\n",
    "    #words_to_remove = {'type ', 'here ', 'words'} # you can insert words you want to remove\n",
    "    #X_data = X_data.apply(lambda x: ' '.join([word for word in x.split() if word not in words_to_remove]))\n",
    "\n",
    "    # filter words of length above n\n",
    "    X_data = X_data.apply(lambda x: ' '.join([word for word in x.split() if len(word) > 1]))\n",
    "        \n",
    "    # 3. word tokenize\n",
    "    X_data = X_data.apply(nltk.word_tokenize)\n",
    "    \n",
    "    # 4. stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    X_data = X_data.apply(lambda x: [stemmer.stem(y) for y in x])\n",
    "    \n",
    "    # ngram\n",
    "    #X_data = X_data.apply(lambda x: list(nltk.ngrams(x, 2))) # you can modify n by replacing 2 with other integers\n",
    "    #X_data = X_data.apply(lambda x: [''.join(i) for i in x])\n",
    "    #print (X_data.iloc[0, 1])\n",
    "    \n",
    "    # join by spaces\n",
    "    X_data = X_data.apply(lambda x: ' '.join(x))\n",
    "       \n",
    "    return X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(X_train, y_train, model='DT'):\n",
    "    \n",
    "    \"\"\"\n",
    "      Model fitting with options of classifiers:\n",
    "      decision tree, svm, knn, naive bayes, random forest, and gradient boosting\n",
    "      \n",
    "      X_train: X train data\n",
    "      y_train: y train data\n",
    "      model: name of classifier\n",
    "      \n",
    "    \"\"\"\n",
    "    \n",
    "    if model=='DT':\n",
    "        DT = DecisionTreeClassifier(max_depth=2)\n",
    "        model = DT.fit(X_train, y_train)\n",
    "    elif model=='SVM':\n",
    "        SVM = SVC(kernel='linear', probability=True)  \n",
    "        model = SVM.fit(X_train, y_train)\n",
    "    elif model=='KNN':\n",
    "        KNN = KNeighborsClassifier(n_neighbors=7)  \n",
    "        model = KNN.fit(X_train, y_train)\n",
    "    elif model=='NB':\n",
    "        NB = MultinomialNB()\n",
    "        model = NB.fit(X_train, y_train)\n",
    "    elif model=='RF':\n",
    "        RF = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "        model = RF.fit(X_train, y_train)\n",
    "    elif model=='GB':\n",
    "        GB = GradientBoostingClassifier()\n",
    "        model = GB.fit(X_train, y_train)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_test, y_pred, eval_model=0):\n",
    "    \n",
    "    \"\"\"\n",
    "      evaluate model performance\n",
    "      \n",
    "      y_test: y test data\n",
    "      y_pred: t prediction score\n",
    "      eval_model: indicator if this funtion is on or off\n",
    "      \n",
    "    \"\"\"\n",
    "    \n",
    "    if eval_model:\n",
    "        print('\\nConfusion Matrix:\\n')\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "        print('\\nClassification Report:\\n')\n",
    "        print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba(model, X_test_trans, X_test, y_test, y_pred, proba_file):\n",
    "    \n",
    "    \"\"\"\n",
    "       Predict probability of each class\n",
    "       \n",
    "       model: trained model with selected classifier\n",
    "       X_test_trans: X test data preprocessed\n",
    "       X_test: original X test data\n",
    "       y_test: original y test data\n",
    "       y_pred: predicted y values\n",
    "       proba_file: output file of probability scores\n",
    "       \n",
    "    \"\"\"\n",
    "    \n",
    "    ## Compute probability\n",
    "    y_prob = model.predict_proba(X_test_trans)\n",
    "    df_prob = pd.DataFrame(data=y_prob, columns=model.classes_)\n",
    "    result = pd.concat([X_test.reset_index(drop=True), df_prob], axis=1, ignore_index=False)\n",
    "\n",
    "    ## Add predicted class to output\n",
    "    result['pred'] = pd.Series(y_pred)\n",
    "\n",
    "    ## Add actual class to output \n",
    "    y_test = y_test.reset_index(drop=True)\n",
    "    result['act'] = y_test\n",
    "\n",
    "    ## Save output\n",
    "    result.to_csv(proba_file, encoding='utf-8-sig', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(input_file, sample_on, sample_type, model_method, eval_on, proba_file):\n",
    "    \n",
    "    \"\"\"\n",
    "       Main function for processing data, model fitting, and prediction\n",
    "       \n",
    "       input_train_file: input train file\n",
    "       input_test_file: input test file\n",
    "       sample_on: indicator of sampling on or off\n",
    "       sample_type: sample type to choose if sample_on is 1\n",
    "       model_method: name of classifier to be applied for model fitting\n",
    "       eval_on: indicator of model evaluation on or off\n",
    "       proba_file: name of output file of probability\n",
    "       \n",
    "    \"\"\"\n",
    "    \n",
    "    ## 1. Load data\n",
    "    X_train, X_test, y_train, y_test = load_data(input_file)\n",
    "    \n",
    "    print('\\nOriginal Data (class, rows):\\n{}'.format(y_train.value_counts()))\n",
    "    \n",
    "    ## 2. Sampling \n",
    "    X_train_samp, y_train_samp = sample_data(X_train, y_train, sampling=sampling_on, sample_method=sampling_type)\n",
    "    \n",
    "    ## 3. Preprocessing \n",
    "    X_train_pro = preprocess_data(X_train_samp)\n",
    "    \n",
    "    count_vect = CountVectorizer()\n",
    "    counts = count_vect.fit_transform(X_train_pro)\n",
    "    transformer = TfidfTransformer(smooth_idf=True, use_idf=True).fit(counts)\n",
    "    X_train_transformed = transformer.transform(counts)\n",
    "    \n",
    "    X_train_trans = X_train_transformed\n",
    "    y_train_trans = y_train_samp\n",
    "\n",
    "    ## 4. Model Fitting\n",
    "    model = fit_model(X_train_trans, y_train_trans, model=model_method)\n",
    "    \n",
    "    ## 5. Prediction\n",
    "    # Transform X_test data\n",
    "    X_test_pro = preprocess_data(X_test)\n",
    "    counts_test = count_vect.transform(X_test_pro)\n",
    "    X_test_trans = transformer.transform(counts_test)\n",
    "    \n",
    "    # Predict output\n",
    "    y_pred = model.predict(X_test_trans)\n",
    "    \n",
    "    ## 6. Evaluating model performance\n",
    "    evaluate_model(y_test, y_pred, eval_model=eval_on)\n",
    "    \n",
    "    ## 7. Probability prediction    \n",
    "    predict_proba(model, X_test_trans, X_test, y_test, y_pred, proba_file=proba_file)\n",
    "    print(\"\\nOutput file:'\" + proba_file + \"' Created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total No of Rows:  42990\n",
      "Total No of Columns:  4\n",
      "\n",
      "Training & Test Size(row, colum):\n",
      "X_train: (34392, 3)\n",
      "X_test: (8598, 3)\n",
      "y_train: (34392,)\n",
      "y_test: (8598,)\n",
      "\n",
      "Original Data (class, rows):\n",
      "2     27281\n",
      "4      1271\n",
      "10      598\n",
      "31      506\n",
      "19      506\n",
      "11      434\n",
      "7       406\n",
      "17      359\n",
      "14      358\n",
      "5       351\n",
      "24      348\n",
      "1       306\n",
      "26      298\n",
      "3       296\n",
      "28      248\n",
      "9       119\n",
      "27      110\n",
      "32       93\n",
      "6        69\n",
      "20       68\n",
      "8        65\n",
      "21       55\n",
      "23       50\n",
      "12       36\n",
      "30       33\n",
      "22       29\n",
      "16       28\n",
      "15       20\n",
      "18       18\n",
      "25       18\n",
      "29       10\n",
      "13        5\n",
      "Name: class, dtype: int64\n",
      "\n",
      "Oversampled Data (class, Rows):\n",
      "32    27281\n",
      "31    27281\n",
      "2     27281\n",
      "3     27281\n",
      "4     27281\n",
      "5     27281\n",
      "6     27281\n",
      "7     27281\n",
      "8     27281\n",
      "9     27281\n",
      "10    27281\n",
      "11    27281\n",
      "12    27281\n",
      "13    27281\n",
      "14    27281\n",
      "15    27281\n",
      "16    27281\n",
      "17    27281\n",
      "18    27281\n",
      "19    27281\n",
      "20    27281\n",
      "21    27281\n",
      "22    27281\n",
      "23    27281\n",
      "24    27281\n",
      "25    27281\n",
      "26    27281\n",
      "27    27281\n",
      "28    27281\n",
      "29    27281\n",
      "30    27281\n",
      "1     27281\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "if __name__== \"__main__\":\n",
    "    \n",
    "    ## Define parameter values\n",
    "    # Filename of input dataset\n",
    "    input_file=path+\"training_labels.csv\" #input_file=\"dbpedia.csv\" \n",
    "    \n",
    "    sampling_on=1             # 0 for no sampling; 1 for sampling\n",
    "    sampling_type='over'      # Use when sampling_on=1; 'over'(oversampling), 'under'(undersampling)\n",
    "\n",
    "    model_type='SVM'           #'DT'(Decision Tree);'SVM'(SVM);'KNN'(KNeighbors);#'NB'(Naive Bayes);\n",
    "                              #'RF'(Random Forest);'GB'(Gradient Boosting)\n",
    "    \n",
    "    eval_on=1                 # 0 for no; 1 for yes (display confusion matrix/classification report)\n",
    "    \n",
    "    output_file = path+ \"/output\" + \"/proba_\" + model_type + \".csv\"  # Filename for probability output \n",
    "    \n",
    "    \n",
    "    ## Main fuction\n",
    "    main(input_file=input_file, \n",
    "         sample_on=sampling_on, \n",
    "         sample_type=sampling_type, \n",
    "         model_method=model_type, \n",
    "         eval_on=eval_on, \n",
    "         proba_file=output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For interpreting errors, inspect records from a given class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75392</th>\n",
       "      <td>fe9543b3-7b2f-4820-8bef-63234813d5ec</td>\n",
       "      <td>Data from the USDA Agricultural Resource Manag...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75393</th>\n",
       "      <td>fe9543b3-7b2f-4820-8bef-63234813d5ec</td>\n",
       "      <td>Data from the USDA Agricultural Resource Manag...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75418</th>\n",
       "      <td>fe9543b3-7b2f-4820-8bef-63234813d5ec</td>\n",
       "      <td>Furthermore, analysis of the data from the USD...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75419</th>\n",
       "      <td>fe9543b3-7b2f-4820-8bef-63234813d5ec</td>\n",
       "      <td>Furthermore, analysis of the data from the USD...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75434</th>\n",
       "      <td>fe9543b3-7b2f-4820-8bef-63234813d5ec</td>\n",
       "      <td>Furthermore, analysis of the data from the USD...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679261</th>\n",
       "      <td>f6afe4c3-fce7-442c-bf33-a1507fad5a50</td>\n",
       "      <td>The data are cross-sectional and come from the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679262</th>\n",
       "      <td>f6afe4c3-fce7-442c-bf33-a1507fad5a50</td>\n",
       "      <td>The data are cross-sectional and come from the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679389</th>\n",
       "      <td>f6afe4c3-fce7-442c-bf33-a1507fad5a50</td>\n",
       "      <td>I use data from the USDA's Agricultural Resour...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679390</th>\n",
       "      <td>f6afe4c3-fce7-442c-bf33-a1507fad5a50</td>\n",
       "      <td>I use data from the USDA's Agricultural Resour...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679391</th>\n",
       "      <td>f6afe4c3-fce7-442c-bf33-a1507fad5a50</td>\n",
       "      <td>I use data from the USDA's Agricultural Resour...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>382 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          id  \\\n",
       "75392   fe9543b3-7b2f-4820-8bef-63234813d5ec   \n",
       "75393   fe9543b3-7b2f-4820-8bef-63234813d5ec   \n",
       "75418   fe9543b3-7b2f-4820-8bef-63234813d5ec   \n",
       "75419   fe9543b3-7b2f-4820-8bef-63234813d5ec   \n",
       "75434   fe9543b3-7b2f-4820-8bef-63234813d5ec   \n",
       "...                                      ...   \n",
       "679261  f6afe4c3-fce7-442c-bf33-a1507fad5a50   \n",
       "679262  f6afe4c3-fce7-442c-bf33-a1507fad5a50   \n",
       "679389  f6afe4c3-fce7-442c-bf33-a1507fad5a50   \n",
       "679390  f6afe4c3-fce7-442c-bf33-a1507fad5a50   \n",
       "679391  f6afe4c3-fce7-442c-bf33-a1507fad5a50   \n",
       "\n",
       "                                                     text  class  \n",
       "75392   Data from the USDA Agricultural Resource Manag...      1  \n",
       "75393   Data from the USDA Agricultural Resource Manag...      1  \n",
       "75418   Furthermore, analysis of the data from the USD...      1  \n",
       "75419   Furthermore, analysis of the data from the USD...      1  \n",
       "75434   Furthermore, analysis of the data from the USD...      1  \n",
       "...                                                   ...    ...  \n",
       "679261  The data are cross-sectional and come from the...      1  \n",
       "679262  The data are cross-sectional and come from the...      1  \n",
       "679389  I use data from the USDA's Agricultural Resour...      1  \n",
       "679390  I use data from the USDA's Agricultural Resour...      1  \n",
       "679391  I use data from the USDA's Agricultural Resour...      1  \n",
       "\n",
       "[382 rows x 3 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['class'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
